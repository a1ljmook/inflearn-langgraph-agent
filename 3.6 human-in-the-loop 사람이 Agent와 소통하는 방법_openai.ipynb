{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6 human-in-the-loop: 사람이 Agent와 소통하는 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AI는 100%의 정확도를 보장하지 않기 때문에, 경우에 따라 사람의 개입이 필요합니다\n",
    "- LangGraph의 [`interrupt`](https://langchain-ai.github.io/langgraph/cloud/how-tos/interrupt_concurrent/) 를 사용하여 사람의 개입을 처리할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\limjangmook\\Desktop\\ANSWER_25\\inflearn-langgraph-agent\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# llm = ChatOllama(model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\"\n",
    "    return a+b\n",
    "\n",
    "@tool\n",
    "def mul(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 곱합니다.\"\"\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "tools = [add, mul, retriever_tool] + search_tools + arxiv_tools + gmail_tools\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='real_estate_tax_retriever', description='부동산 세금 정보 검색기', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=<function create_retriever_tool.<locals>.func at 0x00000202025F63E0>, coroutine=<function create_retriever_tool.<locals>.afunc at 0x00000202025F7D80>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.tools.retriever import create_retriever_tool\n",
    "\n",
    "collection_name = \"real_estate_tax\"\n",
    "embedding_function = HuggingFaceEmbeddings(model=\"BAAI/bge-m3\")\n",
    "vector_store = Chroma(\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embedding_function,\n",
    "    persist_directory=\"./chroma\"\n",
    ")\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever=retriever,\n",
    "    name=\"real_estate_tax_retriever\",\n",
    "    description=\"부동산 세금 정보 검색기\"\n",
    ")\n",
    "retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\limjangmook\\Desktop\\ANSWER_25\\inflearn-langgraph-agent\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_research.py:97: UserWarning: Field name \"output_schema\" in \"TavilyResearch\" shadows an attribute in parent \"BaseTool\"\n",
      "  class TavilyResearch(BaseTool):  # type: ignore[override, override]\n",
      "c:\\Users\\limjangmook\\Desktop\\ANSWER_25\\inflearn-langgraph-agent\\.venv\\Lib\\site-packages\\langchain_tavily\\tavily_research.py:97: UserWarning: Field name \"stream\" in \"TavilyResearch\" shadows an attribute in parent \"BaseTool\"\n",
      "  class TavilyResearch(BaseTool):  # type: ignore[override, override]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DuckDuckGoSearchRun(api_wrapper=DuckDuckGoSearchAPIWrapper(region='wt-wt', safesearch='moderate', time='y', max_results=5, backend='auto', source='text')),\n",
       " TavilySearch(search_depth='advanced', include_images=True, max_results=3, topic='general', include_answer=True, include_raw_content=True, include_image_descriptions=True, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********'), api_base_url=None))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "search_tools = [\n",
    "    DuckDuckGoSearchRun(),\n",
    "    TavilySearch(\n",
    "        max_results=3,\n",
    "        topic=\"general\",\n",
    "        include_answer=True,\n",
    "        include_raw_content=True,\n",
    "        include_images=True,\n",
    "        include_image_descriptions=True,\n",
    "        search_depth=\"advanced\",\n",
    "    )\n",
    "]\n",
    "search_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=3, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=4000)),\n",
       " WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'c:\\\\Users\\\\limjangmook\\\\Desktop\\\\ANSWER_25\\\\inflearn-langgraph-agent\\\\.venv\\\\Lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=3, lang='en', load_all_available_meta=False, doc_content_chars_max=4000))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import ArxivQueryRun, WikipediaQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper, WikipediaAPIWrapper\n",
    "\n",
    "arxiv_tools = [\n",
    "    ArxivQueryRun(api_wrapper=ArxivAPIWrapper(top_k_results=3)),\n",
    "    WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper(top_k_results=3)),\n",
    "]\n",
    "arxiv_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GmailCreateDraft(api_resource=<googleapiclient.discovery.Resource object at 0x000002020478B680>),\n",
       " GmailSendMessage(api_resource=<googleapiclient.discovery.Resource object at 0x000002020478B680>),\n",
       " GmailSearch(api_resource=<googleapiclient.discovery.Resource object at 0x000002020478B680>),\n",
       " GmailGetMessage(api_resource=<googleapiclient.discovery.Resource object at 0x000002020478B680>),\n",
       " GmailGetThread(api_resource=<googleapiclient.discovery.Resource object at 0x000002020478B680>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_community import GmailToolkit\n",
    "from langchain_google_community.gmail.utils import get_google_credentials, build_gmail_service\n",
    "\n",
    "credentials = get_google_credentials(\n",
    "    scopes=[\"https://mail.google.com/\"],\n",
    "    token_file=\"./google/gmail_token.json\",\n",
    "    client_secrets_file=\"./google/gmail_credentials.json\"\n",
    ")\n",
    "api_resource = build_gmail_service(credentials=credentials)\n",
    "gmail_toolkit = GmailToolkit(api_resource=api_resource)\n",
    "gmail_tools = gmail_toolkit.get_tools()\n",
    "gmail_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = [add, mul, retriever_tool] + search_tools + arxiv_tools + gmail_tools\n",
    "tool_node = ToolNode(tools=tools)\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "workflow = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "def agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    이 에이전트 함수는 주어진 state에서 이전 요약과 메시지를 가져와 LLM과 도구를 사용하여 응답 메시지를 생성합니다.\n",
    "    Args:\n",
    "        state (MessagesState): 이전 요약과 메시지 기록을 포함하는 state\n",
    "    Returns:\n",
    "        MessagesState: 응답 메시지를 포함하는 새로운 state\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    summary = state[\"summary\"]\n",
    "\n",
    "    if summary != \"\":\n",
    "        messages = [SystemMessage(content=f\"이전 대화 기록 요약입니다: {summary}\")] + messages\n",
    "    \n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `interrupt`에는 사용자에게 보여주고자 하는 메시지를 dictionary 형태로 작성합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "def human_review(state: AgentState) -> Command[Literal[\"tools\", \"agent\"]]:\n",
    "    \"\"\"\n",
    "    human_review node는 LLM의 도구 호출에 대해 사람의 검토를 요청합니다.\n",
    "    Args:\n",
    "        state (AgentState): 메시지 기록을 포함하는 state\n",
    "    Returns:\n",
    "        Command: 다음 node로 이동하기 위한 Command를 반환합니다.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    tool_call = messages[-1].tool_calls[-1]\n",
    "\n",
    "    review_interrupt = interrupt({\n",
    "        \"question\": \" 이렇게 진행하면 될까요?\",\n",
    "        \"tool_call\": tool_call,\n",
    "    })\n",
    "    review_action = review_interrupt[\"action\"]  # \"continue\", \"update_args\", \"update_tool\"\n",
    "    review_data = review_interrupt.get(\"data\", None)\n",
    "\n",
    "    if review_action == \"continue\":\n",
    "        # 에이전트의 판단이 맞다면, 도구를 사용하기 위해 아무것도 수정하지 않고 \"tools\" 노드로 이동합니다\n",
    "        return Command(goto=\"tools\")\n",
    "    \n",
    "    if review_action == \"update_args\":\n",
    "        # 도구를 더 효율적으로 사용하기 위해 `AIMessage`의 \"tool_calls\" 필드를 업데이트합니다\n",
    "        updated_ai_message = {\n",
    "            \"id\": messages[-1].id,\n",
    "            \"role\": \"ai\",\n",
    "            \"content\": messages[-1].content,\n",
    "            \"tool_calls\": [{\n",
    "                \"id\": tool_call[\"id\"],\n",
    "                \"name\": tool_call[\"name\"],\n",
    "                \"args\": review_data,\n",
    "            }]\n",
    "        }\n",
    "        return Command(goto=\"tools\", update={\"messages\": [updated_ai_message]})\n",
    "\n",
    "    if review_action == \"update_tool\":\n",
    "        # 다른 도구를 사용하기 위해 `ToolMessage`를 업데이트합니다 \n",
    "        updated_tool_message = {\n",
    "            \"tool_call_id\": tool_call[\"id\"],\n",
    "            \"name\": tool_call[\"name\"],\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": review_data,\n",
    "        }\n",
    "        return Command(goto=\"agent\", update={\"messages\": [updated_tool_message]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_messages(state: AgentState):\n",
    "    \"\"\"\n",
    "    주어진 state의 메시지를 요약합니다.\n",
    "    Args:\n",
    "        state (AgentState): 요약과 메시지를 포함하는 state\n",
    "    Returns:\n",
    "        AgentState: 요약된 메시지를 포함하는 state\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    summary = state[\"summary\"]\n",
    "\n",
    "    if summary == \"\":\n",
    "        summary_prompt = f\"\"\"아래 대화 기록을 요약해 주세요:\n",
    "            chat_history: {messages}\"\"\"\n",
    "    else:\n",
    "        summary_prompt = f\"\"\"이전 요약을 포함해서, 아래 대화 기록을 요약해 주세요:\n",
    "            chat_history: {messages}\n",
    "            summary: {summary}\"\"\"\n",
    "    \n",
    "    response = llm_with_tools.invoke(summary_prompt)\n",
    "    return {\"summary\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "def delete_messages(state: AgentState):\n",
    "    \"\"\"\n",
    "    주어진 state에서 오래된 메시지를 삭제합니다.\n",
    "    Args:\n",
    "        state (AgentState): 메시지를 포함하는 state\n",
    "    Returns:\n",
    "        AgentState: 삭제된 메시지를 포함하는 새로운 state\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    deleted_messages = [RemoveMessage(id=message.id) for message in messages[:-3]]\n",
    "    return {\"messages\": deleted_messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: AgentState) -> Literal[\"human_review\", \"summarize_messages\"]:\n",
    "    \"\"\"\n",
    "    주어진 state에 따라 다음 단계로 진행할지 결정합니다.\n",
    "    Args:\n",
    "        state (AgentState): 메시지와 도구 호출 정보를 포함하는 state\n",
    "    Returns:\n",
    "        Literal[\"human_review\", \"summarize_messages\"]: 다음 단계로 \"human_review\" or \"summarize_messages\"를 반환합니다.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    if messages[-1].tool_calls:\n",
    "        return \"human_review\"\n",
    "    return \"summarize_messages\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `node`를 추가하고 `edge`로 연결합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x202047d3110>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "workflow.add_node(\"agent\", agent)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_node(human_review)\n",
    "workflow.add_node(summarize_messages)\n",
    "workflow.add_node(delete_messages)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\"agent\", should_continue, [\"human_review\", \"summarize_messages\"])\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "workflow.add_edge(\"summarize_messages\", \"delete_messages\")\n",
    "workflow.add_edge(\"delete_messages\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `interrupt`로 중단된 시점부터 다시 워크플로우를 재개하기 위해 `checkpointer`가 필요합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from IPython.display import display, Image\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=checkpointer)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"summarize_paper\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "LLM Survey 논문 검색해서 요약해 주세요\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_mBmAGy4h9BqJxPRMkll3Lmpo)\n",
      " Call ID: call_mBmAGy4h9BqJxPRMkll3Lmpo\n",
      "  Args:\n",
      "    query: LLM Survey\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (call_mBmAGy4h9BqJxPRMkll3Lmpo)\n",
      " Call ID: call_mBmAGy4h9BqJxPRMkll3Lmpo\n",
      "  Args:\n",
      "    query: LLM Survey\n"
     ]
    }
   ],
   "source": [
    "query = \"LLM Survey 논문 검색해서 요약해 주세요\"\n",
    "\n",
    "for response in graph.stream(\n",
    "    {\"messages\": [HumanMessage(query)], \"summary\": \"\"},\n",
    "    config=config,\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='LLM Survey 논문 검색해서 요약해 주세요', additional_kwargs={}, response_metadata={}, id='b726fd8c-cb9b-4fbf-90bd-a3b993d9b363'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 1940, 'total_tokens': 1956, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-Cqapj5unOf8VBzlvFVphL0gKdfB90', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b5496-0a1e-7e32-8c81-20819225b86d-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'LLM Survey'}, 'id': 'call_mBmAGy4h9BqJxPRMkll3Lmpo', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1940, 'output_tokens': 16, 'total_tokens': 1956, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'arxiv',\n",
       " 'args': {'query': 'LLM Survey'},\n",
       " 'id': 'call_mBmAGy4h9BqJxPRMkll3Lmpo',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values[\"messages\"][-1].tool_calls[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human_review': {'messages': [{'tool_call_id': 'call_mBmAGy4h9BqJxPRMkll3Lmpo', 'name': 'arxiv', 'role': 'tool', 'content': 'arxiv말고 web에서 검색해 주세요'}]}}\n",
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 1973, 'total_tokens': 1996, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1920}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_c4585b5b9c', 'id': 'chatcmpl-Cqapq1bDxKNE2P8XNVMW8Gb1WjWxD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b5496-276c-70c2-949e-9d532d5e9261-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'LLM Survey', 'search_depth': 'advanced'}, 'id': 'call_afJIDcLuyfzldcrw3r6CqXzC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1973, 'output_tokens': 23, 'total_tokens': 1996, 'input_token_details': {'audio': 0, 'cache_read': 1920}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "{'__interrupt__': (Interrupt(value={'question': ' 이렇게 진행하면 될까요?', 'tool_call': {'name': 'tavily_search', 'args': {'query': 'LLM Survey', 'search_depth': 'advanced'}, 'id': 'call_afJIDcLuyfzldcrw3r6CqXzC', 'type': 'tool_call'}}, id='ad58d681f19955a72621b35d3669ebb0'),)}\n"
     ]
    }
   ],
   "source": [
    "for response in graph.stream(\n",
    "    Command(resume={\"action\": \"update_tool\", \"data\": \"arxiv말고 web에서 검색해 주세요\"}),\n",
    "    config=config,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='LLM Survey 논문 검색해서 요약해 주세요', additional_kwargs={}, response_metadata={}, id='b726fd8c-cb9b-4fbf-90bd-a3b993d9b363'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 1940, 'total_tokens': 1956, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-Cqapj5unOf8VBzlvFVphL0gKdfB90', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b5496-0a1e-7e32-8c81-20819225b86d-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'LLM Survey'}, 'id': 'call_mBmAGy4h9BqJxPRMkll3Lmpo', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1940, 'output_tokens': 16, 'total_tokens': 1956, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='arxiv말고 web에서 검색해 주세요', name='arxiv', id='b1d924ed-8166-4ba0-b048-933e1cae0ed8', tool_call_id='call_mBmAGy4h9BqJxPRMkll3Lmpo'),\n",
       " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 1973, 'total_tokens': 1996, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1920}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_c4585b5b9c', 'id': 'chatcmpl-Cqapq1bDxKNE2P8XNVMW8Gb1WjWxD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b5496-276c-70c2-949e-9d532d5e9261-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'LLM Survey', 'search_depth': 'advanced'}, 'id': 'call_afJIDcLuyfzldcrw3r6CqXzC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1973, 'output_tokens': 23, 'total_tokens': 1996, 'input_token_details': {'audio': 0, 'cache_read': 1920}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_search',\n",
       " 'args': {'query': 'LLM Survey', 'search_depth': 'advanced'},\n",
       " 'id': 'call_afJIDcLuyfzldcrw3r6CqXzC',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values[\"messages\"][-1].tool_calls[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human_review': None}\n",
      "{'tools': {'messages': [ToolMessage(content='{\"query\": \"LLM Survey\", \"follow_up_questions\": null, \"answer\": \"Large language models (LLMs) revolutionize AI development, with key advances in pre-training, adaptation, utilization, and evaluation. They assist in survey research by generating responses but cannot address sampling bias. A comprehensive survey collection exists, covering over 150 surveys on LLMs.\", \"images\": [{\"url\": \"https://pic1.zhimg.com/v2-b78c8a045bea1efdee800de108066cb0_r.jpg\", \"description\": \"The image compares in-context learning and chain-of-thought prompting with examples of mathematical reasoning questions, demonstrations, and test queries, illustrating their differences in approach.\"}, {\"url\": \"https://pic3.zhimg.com/v2-8be80510e165e6de7f8d657dfbd09516_r.jpg\", \"description\": \"A colorful circular diagram categorizes aspects of large language model evaluation, including knowledge and capability, alignment evaluation, safety, robustness evaluation, and specialized LLMs.\"}, {\"url\": \"https://gkwang-1251992353.cos.ap-shanghai.myqcloud.com/blog/post/llmsurvey/LLM_Survey_Corpus.png\", \"description\": \"The table lists various data sources used in an LLM survey, detailing their size, source type, and latest update times, with references highlighted in green.\"}, {\"url\": \"https://milanlproc.github.io/publication/2025-llm-survey-simulation/featured.png\", \"description\": \"The diagram illustrates a framework for Large Language Model (LLM) survey-based question answering, showing inputs from countries and multiple-choice questions, training processes involving human feedback and option distribution, and methods of inference including direct answer prediction and an alternative approach using unseen questions and countries.\"}, {\"url\": \"https://yellow-cdn.veclightyear.com/b66f4b6e/cf14b767-adef-48d7-83e7-6e6dcbb46f30.png\", \"description\": \"Various aspects of large language model evaluation, including knowledge and capability, alignment evaluation, safety, specialized LLM applications, and evaluation organization, are illustrated in a colorful circular diagram.\"}], \"results\": [{\"url\": \"https://arxiv.org/abs/2303.18223\", \"title\": \"[2303.18223] A Survey of Large Language Models\", \"content\": \"revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.\", \"score\": 0.798077, \"raw_content\": \"We gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors. [Donate](https://info.arxiv.org/about/donate.html)\\\\n\\\\n> [cs](/list/cs/recent) > arXiv:2303.18223\\\\n\\\\n\\\\n\\\\n# Computer Science > Computation and Language\\\\n\\\\n**arXiv:2303.18223** (cs)\\\\n\\\\n[Submitted on 31 Mar 2023 ([v1](https://arxiv.org/abs/2303.18223v1)), last revised 11 Mar 2025 (this version, v16)]\\\\n\\\\n# Title:A Survey of Large Language Models\\\\n\\\\nAuthors:[Wayne Xin Zhao](https://arxiv.org/search/cs?searchtype=author&query=Zhao,+W+X), [Kun Zhou](https://arxiv.org/search/cs?searchtype=author&query=Zhou,+K), [Junyi Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+J), [Tianyi Tang](https://arxiv.org/search/cs?searchtype=author&query=Tang,+T), [Xiaolei Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+X), [Yupeng Hou](https://arxiv.org/search/cs?searchtype=author&query=Hou,+Y), [Yingqian Min](https://arxiv.org/search/cs?searchtype=author&query=Min,+Y), [Beichen Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+B), [Junjie Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+J), [Zican Dong](https://arxiv.org/search/cs?searchtype=author&query=Dong,+Z), [Yifan Du](https://arxiv.org/search/cs?searchtype=author&query=Du,+Y), [Chen Yang](https://arxiv.org/search/cs?searchtype=author&query=Yang,+C), [Yushuo Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen,+Y), [Zhipeng Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen,+Z), [Jinhao Jiang](https://arxiv.org/search/cs?searchtype=author&query=Jiang,+J), [Ruiyang Ren](https://arxiv.org/search/cs?searchtype=author&query=Ren,+R), [Yifan Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+Y), [Xinyu Tang](https://arxiv.org/search/cs?searchtype=author&query=Tang,+X), [Zikang Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+Z), [Peiyu Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+P), [Jian-Yun Nie](https://arxiv.org/search/cs?searchtype=author&query=Nie,+J), [Ji-Rong Wen](https://arxiv.org/search/cs?searchtype=author&query=Wen,+J)\\\\n\\\\nView a PDF of the paper titled A Survey of Large Language Models, by Wayne Xin Zhao and 20 other authors\\\\n\\\\n[View PDF](/pdf/2303.18223) [HTML (experimental)](https://arxiv.org/html/2303.18223v16)\\\\n> Abstract:Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| Comments: | ongoing work; 144 pages, 1081 citations |\\\\n| Subjects: | Computation and Language (cs.CL); Artificial Intelligence (cs.AI) |\\\\n| Cite as: | [arXiv:2303.18223](https://arxiv.org/abs/2303.18223) [cs.CL] |\\\\n|  | (or  [arXiv:2303.18223v16](https://arxiv.org/abs/2303.18223v16) [cs.CL] for this version) |\\\\n|  | <https://doi.org/10.48550/arXiv.2303.18223> arXiv-issued DOI via DataCite |\\\\n\\\\n## Submission history\\\\n\\\\nFrom: Kun Zhou [[view email](/show-email/281bf9f9/2303.18223)]   \\\\n **[[v1]](/abs/2303.18223v1)** Fri, 31 Mar 2023 17:28:46 UTC (991 KB)  \\\\n **[[v2]](/abs/2303.18223v2)** Sun, 9 Apr 2023 15:49:09 UTC (1,306 KB)  \\\\n **[[v3]](/abs/2303.18223v3)** Tue, 11 Apr 2023 16:20:17 UTC (1,305 KB)  \\\\n **[[v4]](/abs/2303.18223v4)** Wed, 12 Apr 2023 16:13:54 UTC (1,310 KB)  \\\\n **[[v5]](/abs/2303.18223v5)** Sun, 16 Apr 2023 16:42:37 UTC (1,678 KB)  \\\\n **[[v6]](/abs/2303.18223v6)** Mon, 24 Apr 2023 16:53:57 UTC (2,528 KB)  \\\\n **[[v7]](/abs/2303.18223v7)** Tue, 25 Apr 2023 14:42:36 UTC (2,528 KB)  \\\\n **[[v8]](/abs/2303.18223v8)** Thu, 27 Apr 2023 15:54:48 UTC (2,533 KB)  \\\\n **[[v9]](/abs/2303.18223v9)** Fri, 28 Apr 2023 15:39:09 UTC (2,534 KB)  \\\\n **[[v10]](/abs/2303.18223v10)** Sun, 7 May 2023 17:59:15 UTC (2,031 KB)  \\\\n **[[v11]](/abs/2303.18223v11)** Thu, 29 Jun 2023 16:09:05 UTC (4,226 KB)  \\\\n **[[v12]](/abs/2303.18223v12)** Mon, 11 Sep 2023 15:13:59 UTC (4,687 KB)  \\\\n **[[v13]](/abs/2303.18223v13)** Fri, 24 Nov 2023 13:57:45 UTC (6,600 KB)  \\\\n **[[v14]](/abs/2303.18223v14)** Tue, 24 Sep 2024 07:02:59 UTC (5,852 KB)  \\\\n **[[v15]](/abs/2303.18223v15)** Sun, 13 Oct 2024 06:11:31 UTC (5,852 KB)  \\\\n **[v16]** Tue, 11 Mar 2025 16:51:11 UTC (7,340 KB)\\\\n\\\\nFull-text links:\\\\n\\\\n## Access Paper:\\\\n\\\\nView a PDF of the paper titled A Survey of Large Language Models, by Wayne Xin Zhao and 20 other authors\\\\n\\\\n* [View PDF](/pdf/2303.18223)\\\\n* [HTML (experimental)](https://arxiv.org/html/2303.18223v16)\\\\n* [TeX Source](/src/2303.18223)\\\\n\\\\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/ \\\\\"Rights to this article\\\\\")\\\\n\\\\nCurrent browse context:\\\\n\\\\ncs.CL\\\\n\\\\n[<\\xa0prev](/prevnext?id=2303.18223&function=prev&context=cs.CL \\\\\"previous in cs.CL (accesskey p)\\\\\")  \\xa0 | \\xa0  [next\\xa0>](/prevnext?id=2303.18223&function=next&context=cs.CL \\\\\"next in cs.CL (accesskey n)\\\\\")\\\\n\\\\n[new](/list/cs.CL/new)  |  [recent](/list/cs.CL/recent)  | [2023-03](/list/cs.CL/2023-03)\\\\n\\\\nChange to browse by:\\\\n\\\\n[cs](/abs/2303.18223?context=cs)  \\\\n [cs.AI](/abs/2303.18223?context=cs.AI)\\\\n\\\\n### References & Citations\\\\n\\\\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2303.18223)\\\\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2303.18223)\\\\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2303.18223)\\\\n\\\\n### [1 blog link](/tb/2303.18223)\\\\n\\\\n([what is this?](https://info.arxiv.org/help/trackback.html))\\\\n\\\\nexport BibTeX citation Loading...\\\\n\\\\n## BibTeX formatted citation\\\\n\\\\n×\\\\n\\\\nData provided by:\\\\n\\\\n### Bookmark\\\\n\\\\n# Bibliographic and Citation Tools\\\\n\\\\nBibliographic Explorer *([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\\\\n\\\\nConnected Papers *([What is Connected Papers?](https://www.connectedpapers.com/about))*\\\\n\\\\nLitmaps *([What is Litmaps?](https://www.litmaps.co/))*\\\\n\\\\nscite Smart Citations *([What are Smart Citations?](https://www.scite.ai/))*\\\\n\\\\n# Code, Data and Media Associated with this Article\\\\n\\\\nalphaXiv *([What is alphaXiv?](https://alphaxiv.org/))*\\\\n\\\\nCatalyzeX Code Finder for Papers *([What is CatalyzeX?](https://www.catalyzex.com))*\\\\n\\\\nDagsHub *([What is DagsHub?](https://dagshub.com/))*\\\\n\\\\nGotit.pub *([What is GotitPub?](http://gotit.pub/faq))*\\\\n\\\\nHugging Face *([What is Huggingface?](https://huggingface.co/huggingface))*\\\\n\\\\nPapers with Code *([What is Papers with Code?](https://paperswithcode.com/))*\\\\n\\\\nScienceCast *([What is ScienceCast?](https://sciencecast.org/welcome))*\\\\n\\\\n# Demos\\\\n\\\\nReplicate *([What is Replicate?](https://replicate.com/docs/arxiv/about))*\\\\n\\\\nHugging Face Spaces *([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\\\\n\\\\nTXYZ.AI *([What is TXYZ.AI?](https://txyz.ai))*\\\\n\\\\n# Recommenders and Search Tools\\\\n\\\\nInfluence Flower *([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\\\\n\\\\nCORE Recommender *([What is CORE?](https://core.ac.uk/services/recommender))*\\\\n\\\\n* Author\\\\n* Venue\\\\n* Institution\\\\n* Topic\\\\n\\\\n# arXivLabs: experimental projects with community collaborators\\\\n\\\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\\\\n\\\\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\\\\n\\\\nHave an idea for a project that will add value for arXiv\\'s community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\\\\n\\\\n[Which authors of this paper are endorsers?](/auth/show-endorsers/2303.18223) | [Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html))\"}, {\"url\": \"https://www.sciencedirect.com/science/article/pii/S2949719123000171\", \"title\": \"Employing large language models in survey research - ScienceDirect\", \"content\": \"This article discusses the promising potential of employing large language models (LLMs) for survey research, including generating responses to survey items. LLMs can address some of the challenges associated with survey research regarding question-wording and response bias. They can address issues relating to a lack of clarity and understanding but cannot yet correct for sampling or nonresponse bias challenges. While LLMs can assist with some of the challenges with survey research, at present,\", \"score\": 0.7672197, \"raw_content\": \"[Skip to article](#screen-reader-main-title)\\\\n\\\\n\\\\n[My account](/user/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS2949719123000171&from=globalheader)\\\\n\\\\n[Sign in](/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS2949719123000171)\\\\n\\\\n* View\\xa0**PDF**\\\\n\\\\n## [Natural Language Processing Journal](/journal/natural-language-processing-journal \\\\\"Go to Natural Language Processing Journal on ScienceDirect\\\\\")\\\\n\\\\n[Volume 4](/journal/natural-language-processing-journal/vol/4/suppl/C \\\\\"Go to table of contents for this volume/issue\\\\\"), September 2023, 100020\\\\n\\\\n# Employing large language models in survey research\\\\n\\\\nAuthor links open overlay panel, ,\\\\n\\\\n[https://doi.org/10.1016/j.nlp.2023.100020](https://doi.org/10.1016/j.nlp.2023.100020 \\\\\"Persistent link using digital object identifier\\\\\")[Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=S2949719123000171&orderBeanReset=true)\\\\n\\\\nUnder a Creative Commons [license](http://creativecommons.org/licenses/by/4.0/)\\\\n\\\\nOpen access\\\\n\\\\n## Abstract\\\\n\\\\nThis article discusses the promising potential of employing large language models (LLMs) for survey research, including generating responses to survey items. LLMs can address some of the challenges associated with survey research regarding question-wording and response bias. They can address issues relating to a lack of clarity and understanding but cannot yet correct for sampling or nonresponse bias challenges. While LLMs can assist with some of the challenges with survey research, at present, LLMs need to be used in conjunction with other methods and approaches. With thoughtful and nuanced approaches to development, LLMs can be used responsibly and beneficially while minimizing the associated risks.\\\\n\\\\n\\\\n\\\\n## Keywords\\\\n\\\\nSurvey research\\\\n\\\\nLarge language models\\\\n\\\\nSurvey data\\\\n\\\\nSurveys\\\\n\\\\nLLM survey respondents\\\\n\\\\n## Cited by (0)\\\\n\\\\n© 2023 The Author(s). Published by Elsevier B.V.\\\\n\\\\n \"}, {\"url\": \"https://github.com/NiuTrans/ABigSurveyOfLLMs\", \"title\": \"NiuTrans/ABigSurveyOfLLMs: A collection of 150+ surveys on LLMs\", \"content\": \"Large language models (LLMs) are making sweeping advances across many fields of artificial intelligence. As a result, research interest and progress in LLMs have exploded. There are now hundreds of research papers on LLMs published in various conferences or posted to open-access archives every day. Given the significant growth in LLM-related papers, this work compiles surveys on LLMs to provide a comprehensive overview of the field. Most of these surveys have been published or posted in the [...] Security and Privacy Challenges of Large Language Models: A Survey, arXiv 2024.01 [Paper]\\\\n Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks, arXiv 2023.10 [Paper]\\\\n A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly, arXiv 2023.12 [Paper]\\\\n Tricking LLMs into Disobedience: Formalizing, Analyzing, and Detecting Jailbreaks, arXiv 2023.05 [Paper] [...] | Name | Name | Last commit message | Last commit date |\\\\n ---  --- |\\\\n| Latest commit   History25 Commits |\\\\n| LICENSE | LICENSE |  |  |\\\\n| README.md | README.md |  |  |\\\\n|  |\\\\n\\\\n## Repository files navigation\\\\n\\\\n# A Survey of LLM Surveys\", \"score\": 0.73846215, \"raw_content\": \"[Skip to content](#start-of-content)   \\\\n\\\\n\\\\n\\\\n## Navigation Menu\\\\n\\\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FNiuTrans%2FABigSurveyOfLLMs) \\\\n\\\\nAppearance settings\\\\n\\\\n# Search code, repositories, users, issues, pull requests...\\\\n\\\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\\\n\\\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FNiuTrans%2FABigSurveyOfLLMs)\\\\n\\\\n [Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=NiuTrans%2FABigSurveyOfLLMs) \\\\n\\\\nAppearance settings\\\\n\\\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\\\n\\\\n{{ message }}\\\\n\\\\n[NiuTrans](/NiuTrans)   /  **[ABigSurveyOfLLMs](/NiuTrans/ABigSurveyOfLLMs)**  Public\\\\n\\\\n* [Notifications](/login?return_to=%2FNiuTrans%2FABigSurveyOfLLMs)  You must be signed in to change notification settings\\\\n* [Fork 26](/login?return_to=%2FNiuTrans%2FABigSurveyOfLLMs)\\\\n* [Star  342](/login?return_to=%2FNiuTrans%2FABigSurveyOfLLMs)\\\\n\\\\nA collection of 150+ surveys on LLMs\\\\n\\\\n### License\\\\n\\\\n[CC0-1.0 license](/NiuTrans/ABigSurveyOfLLMs/blob/main/LICENSE)\\\\n\\\\n[342 stars](/NiuTrans/ABigSurveyOfLLMs/stargazers)   [26 forks](/NiuTrans/ABigSurveyOfLLMs/forks)   [Branches](/NiuTrans/ABigSurveyOfLLMs/branches)   [Tags](/NiuTrans/ABigSurveyOfLLMs/tags)   [Activity](/NiuTrans/ABigSurveyOfLLMs/activity)\\\\n\\\\n[Star](/login?return_to=%2FNiuTrans%2FABigSurveyOfLLMs)\\\\n\\\\n[Notifications](/login?return_to=%2FNiuTrans%2FABigSurveyOfLLMs)  You must be signed in to change notification settings\\\\n\\\\n# NiuTrans/ABigSurveyOfLLMs\\\\n\\\\n[Branches](/NiuTrans/ABigSurveyOfLLMs/branches)[Tags](/NiuTrans/ABigSurveyOfLLMs/tags)\\\\n\\\\nOpen more actions menu\\\\n\\\\n## Folders and files\\\\n\\\\n| Name | Name | Last commit message | Last commit date |\\\\n| --- | --- | --- | --- |\\\\n| Latest commit   History[25 Commits](/NiuTrans/ABigSurveyOfLLMs/commits/main/) |\\\\n| [LICENSE](/NiuTrans/ABigSurveyOfLLMs/blob/main/LICENSE \\\\\"LICENSE\\\\\") | [LICENSE](/NiuTrans/ABigSurveyOfLLMs/blob/main/LICENSE \\\\\"LICENSE\\\\\") |  |  |\\\\n| [README.md](/NiuTrans/ABigSurveyOfLLMs/blob/main/README.md \\\\\"README.md\\\\\") | [README.md](/NiuTrans/ABigSurveyOfLLMs/blob/main/README.md \\\\\"README.md\\\\\") |  |  |\\\\n|  |\\\\n\\\\n## Repository files navigation\\\\n\\\\n# A Survey of LLM Surveys\\\\n\\\\nLarge language models (LLMs) are making sweeping advances across many fields of artificial intelligence. As a result, research interest and progress in LLMs have exploded. There are now hundreds of research papers on LLMs published in various conferences or posted to open-access archives every day. Given the significant growth in LLM-related papers, this work compiles surveys on LLMs to provide a comprehensive overview of the field. Most of these surveys have been published or posted in the past few years, so this collection is relatively new. We hope that our compilation can be helpful for people who want to get a quick understanding of the field.\\\\n\\\\n## Outline\\\\n\\\\n* [General Surveys](#section1)\\\\n* [Transformers](#section2)\\\\n* [Alignment](#section3)\\\\n* [Prompt Learning](#section4)\\\\n  + [In-context Learning](#section5)\\\\n  + [Chain of Thought](#section6)\\\\n  + [Prompt Engineering](#section7)\\\\n  + [Reasoning](#section8)\\\\n* [Data](#section9)\\\\n* [Evaluation](#section10)\\\\n* [Societal Issues](#section11)\\\\n* [Safety](#section12)\\\\n  + [Source Detection](#section13)\\\\n  + [Security](#section14)\\\\n* [Misinformation](#section15)\\\\n  + [Hallucinations](#section16)\\\\n  + [Factuality](#section17)\\\\n* [Attributes of LLMs](#section18)\\\\n* [Efficient LLMs](#section19)\\\\n* [Learning Methods\\xa0for LLMs](#section20)\\\\n* [Multimodal LLMs](#section21)\\\\n* [Knowledge Based LLMs](#section22)\\\\n  + [Retrieval-Augmented LLMs](#section23)\\\\n  + [Knowledge Editing](#section24)\\\\n* [Extension of LLMs](#section25)\\\\n  + [LLMs with\\xa0Tools](#section26)\\\\n  + [LLMs and\\xa0Interactions](#section27)\\\\n* [Long Sequence LLMs](#section28)\\\\n* [LLMs Applications](#section29)\\\\n  + [Education](#section30)\\\\n  + [Law](#section31)\\\\n  + [Healthcare](#section32)\\\\n  + [Games](#section33)\\\\n  + [NLP Tasks](#section34)\\\\n  + [Software Engineering](#section35)\\\\n  + [Recommender Systems](#section36)\\\\n  + [Graphs](#section37)\\\\n  + [Other](#section38)\\\\n\\\\n## Survey List\\\\n\\\\n#### General Surveys\\\\n\\\\n* **Large Language Models: A Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.06196)]\\\\n* **A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.04226)]\\\\n* **A Survey of Large Language Models**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2303.18223)] [[GitHub](https://github.com/RUCAIBox/LLMSurvey)]\\\\n* **Foundations of Large Language Models**, arXiv 2025.01 [[paper](https://arxiv.org/abs/2501.09223)]\\\\n* **Challenges and Applications of Large Language Models**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.10169)]\\\\n* **Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond**, arXiv 2023.04 [[Paper](https://arxiv.org/abs/2304.13712)] [[GitHub](https://github.com/Mooler0410/LLMsPracticalGuide)]\\\\n* **A Survey on Large Language Models: Applications, Challenges, Limitations, and Practical Usage**, TechRxiv 2023.07 [[Paper](https://www.techrxiv.org/doi/full/10.36227/techrxiv.23589741.v1)] [[GitHub](https://github.com/anas-zafar/LLM-Survey)]\\\\n* **A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT**, arXiv 2023.05 [[Paper](https://arxiv.org/abs/2302.09419)]\\\\n* **A Comprehensive Overview of Large Language Models**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.06435v8)] [[GitHub](https://github.com/humza909/LLM_Survey)]\\\\n* **Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**, ACM Computing Surveys 2023.01 [[Paper](https://dl.acm.org/doi/full/10.1145/3560815)]\\\\n\\\\n#### Transformers\\\\n\\\\n* **A survey of transformers**, arXiv 2022.10 [[Paper](https://www.sciencedirect.com/science/article/pii/S2666651022000146)]\\\\n* **Introduction to Transformers: an NLP Perspective**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.17633)] [[GitHub](https://github.com/NiuTrans/Introduction-to-Transformers)]\\\\n* **Efficient Transformers: A Survey**, arXiv 2022.12 [[Paper](https://dl.acm.org/doi/full/10.1145/3530811)]\\\\n* **A Practical Survey on Faster and Lighter Transformers**, arXiv 2023.07 [[Paper](https://dl.acm.org/doi/abs/10.1145/3586074)]\\\\n* **Attention Mechanism, Transformers, BERT, and GPT: Tutorial and Survey**, arXiv 2020.12 [[Paper](https://osf.io/preprints/osf/m6gcn)]\\\\n\\\\n#### Alignment\\\\n\\\\n* **Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation**, arXiv 2023.06 [[Paper](https://arxiv.org/abs/2305.00955)]\\\\n* **AI Alignment: A Comprehensive Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2310.19852)]\\\\n* **Large Language Model Alignment: A Survey**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.15025)]\\\\n* **From Instructions to Intrinsic Human Values -- A Survey of Alignment Goals for Big Models**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2308.12014)] [[GitHub](https://github.com/ValueCompass/Alignment-Goal-Survey)]\\\\n* **Aligning Large Language Models with Human: A Survey**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.12966)] [[GitHub](https://github.com/GaryYufei/AlignLLMHumanSurvey)]\\\\n* **Instruction Tuning for Large Language Models: A Survey**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.10792)]\\\\n* **A Comprehensive Survey on Instruction Following**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2303.10475v7)] [[GitHub](https://github.com/RenzeLou/awesome-instruction-learning)]\\\\n\\\\n#### Prompt Learning\\\\n\\\\n###### In-context Learning\\\\n\\\\n* **A Practical Survey on Zero-shot Prompt Design for In-context Learning**, ranlp 2023.09 [[Paper](https://aclanthology.org/2023.ranlp-1.69/)]\\\\n* **A Survey on In-context Learning**, arXiv 2023.06 [[Paper](https://arxiv.org/abs/2301.00234)]\\\\n\\\\n###### Chain of Thought\\\\n\\\\n* **A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2309.15402)] [[GitHub](https://github.com/zchuz/CoT-Reasoning-Survey)]\\\\n* **Towards Better Chain-of-Thought Prompting Strategies: A Survey**, arXiv 2023.10 [[Paper](https://doi.org/10.48550/arXiv.2310.04959)]\\\\n* **Igniting Language Intelligence: The Hitchhiker\\'s Guide From Chain-of-Thought Reasoning to Language Agents**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.11797)] [[GitHub](https://github.com/Zoeyyao27/CoT-Igniting-Agent)]\\\\n\\\\n###### Prompt Engineering\\\\n\\\\n* **Prompting Frameworks for Large Language Models: A Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.12785)] [[GitHub](https://github.com/lxx0628/Prompting-Framework-Survey)]\\\\n* **Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.14735)]\\\\n\\\\n###### Reasoning\\\\n\\\\n* **Towards Reasoning in Large Language Models: A Survey**, arXiv 2022.12 [[Paper](https://arxiv.org/abs/2212.10403)] [[GitHub](https://github.com/jeffhj/LM-reasoning)]\\\\n* **A Survey of Reasoning with Foundation Models**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.11562)] [[GitHub](https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models)]\\\\n\\\\n#### Data\\\\n\\\\n* **Data Management For Large Language Models: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.01700)] [[GitHub](https://github.com/ZigeW/data_management_LLM)]\\\\n* **A Survey on Data Selection for Language Models**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.16827)]\\\\n* **Datasets for Large Language Models: A Comprehensive Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.18041)] [[GitHub](https://github.com/lmmlzn/Awesome-LLMs-Datasets)]\\\\n* **Large Language Models for Data Annotation: A Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.13446)] [[GitHub](https://github.com/Zhen-Tan-dmml/LLM4Annotation)]\\\\n* **A Survey on Data Selection for LLM Instruction Tuning**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.05123)]\\\\n* **A Survey on Knowledge Distillation of Large Language Models**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.13116)]\\\\n\\\\n#### Evaluation\\\\n\\\\n* **Evaluating Large Language Models: A Comprehensive Survey**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.19736)] [[GitHub](https://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers)]\\\\n* **A Survey on Evaluation of Large Language Models**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.03109)] [[GitHub](https://github.com/MLGroupJLU/LLM-eval-survey)]\\\\n* **Baby steps in evaluating the capacities of large language models**, arXiv 2023.06 [[Paper](https://www.nature.com/articles/s44159-023-00211-x)]\\\\n\\\\n#### Societal Issues\\\\n\\\\n* **A Survey on Fairness in Large Language Models**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.10149)]\\\\n* **Large Language Models as Subpopulation Representative Models: A Review**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.17888)]\\\\n* **Perception, performance, and detectability of conversational artificial intelligence across 32 university courses**, SCI REP-UK 2023.08 [[Paper](https://www.nature.com/articles/s41598-023-38964-3)]\\\\n* **Should chatgpt be biased? challenges and risks of bias in large language models**, arXiv 2023.04 [[Paper](https://arxiv.org/abs/2304.03738)]\\\\n* **Bias and Fairness in Large Language Models: A Survey**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.00770)] [[GitHub](https://github.com/i-gallegos/Fair-LLM-Benchmark)]\\\\n\\\\n#### Safety\\\\n\\\\n###### Source Detection\\\\n\\\\n* **A Survey on Detection of LLMs-Generated Content**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.15654)] [[GitHub](https://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection)]\\\\n* **A Survey on LLM-generated Text Detection: Necessity, Methods, and Future Directions**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.14724)] [[GitHub](https://github.com/NLP2CT/LLM-generated-Text-Detection)]\\\\n* **Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.07689)]\\\\n* **The Science of Detecting LLM-Generated Texts**, arXiv 2023.02 [[Paper](https://arxiv.org/abs/2303.07205)]\\\\n\\\\n###### Security\\\\n\\\\n* **Security and Privacy Challenges of Large Language Models: A Survey**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2402.00888)]\\\\n* **Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.10844)]\\\\n* **A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.02003)]\\\\n* **Tricking LLMs into Disobedience: Formalizing, Analyzing, and Detecting Jailbreaks**, arXiv 2023.05 [[Paper](https://arxiv.org/abs/2305.14965)]\\\\n* **A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation**, arXiv 2023.05 [[Paper](https://arxiv.org/abs/2305.11391)]\\\\n\\\\n#### Misinformation\\\\n\\\\n###### Hallucinations\\\\n\\\\n* **Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.07914)]\\\\n* **A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.05232)] [[GitHub](https://github.com/LuckyyySTA/Awesome-LLM-hallucination)]\\\\n* **A Survey of Hallucination in “Large” Foundation Models**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.05922)] [[GitHub](https://github.com/vr25/hallucination-foundation-model-survey)]\\\\n* **Siren\\'s Song in the AI Ocean: A Survey on Hallucination in Large Language Models**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.01219)] [[GitHub](https://github.com/HillZhang1999/llm-hallucination-survey)]\\\\n* **Cognitive Mirage: A Review of Hallucinations in Large Language Models**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.06794)] [[GitHub](https://github.com/hongbinye/Cognitive-Mirage-Hallucinations-in-LLMs)]\\\\n* **Augmenting LLMs with Knowledge: A survey on hallucination prevention**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.16459)]\\\\n* **A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.01313)]\\\\n\\\\n###### Factuality\\\\n\\\\n* **Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models\\' Alignment**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.05374)]\\\\n* **Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.07521)] [[GitHub](https://github.com/wangcunxiang/LLM-Factuality-Survey)]\\\\n* **Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.16570)]\\\\n\\\\n#### Attributes of LLMs\\\\n\\\\n* **Explainability for Large Language Models: A Survey**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.01029)]\\\\n* **The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilitie**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.00237)]\\\\n* **From Understanding to Utilization: A Survey on Explainability for Large Language Models**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.12874)]\\\\n* **A Survey of Large Language Models Attribution**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.03731)] [[GitHub](https://github.com/HITsz-TMG/awesome-llm-attributions)]\\\\n* **A Survey of Language Model Confidence Estimation and Calibration**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.08298)]\\\\n* **Shortcut Learning of Large Language Models in Natural Language Understanding**, COMMUN ACM 2023.12 [[Paper](https://dl.acm.org/doi/10.1145/3596490)]\\\\n* **Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.03188)] [[GitHub](https://github.com/teacherpeterpan/self-correction-llm-papers)]\\\\n\\\\n#### Efficient LLMs\\\\n\\\\n* **Efficient Large Language Models: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.03863)] [[GitHub](https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey)]\\\\n* **LLM Inference Unveiled: Survey and Roofline Model Insights**, arXiv 2024.03 [[Paper](https://arxiv.org/abs/2402.16363)]\\\\n* **Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.15234)]\\\\n* **A Survey on Model Compression for Large Language Models**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.07633)]\\\\n* **A Comprehensive Survey of Compression Algorithms for Language Models**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.15347)]\\\\n* **The Efficiency Spectrum of Large Language Models: An Algorithmic Survey**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.10844)] [[GitHub](https://github.com/tding1/Efficient-LLM-Survey)]\\\\n* **Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.12148)]\\\\n* **Model Compression and Efficient Inference for Large Language Models: A Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.09748)]\\\\n* **Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.07851)] [[GitHub](https://github.com/hemingkx/SpeculativeDecodingPapers)]\\\\n* **A Survey on Hardware Accelerators for Large Language Models**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.09890)]\\\\n\\\\n#### Learning Methods\\xa0for LLMs\\\\n\\\\n* **Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.15766)]\\\\n* **Continual Learning with Pre-Trained Models: A Survey**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.16386)] [[GitHub](https://github.com/sun-hailong/LAMDA-PILOT)]\\\\n* **Continual Learning for Large Language Models: A Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.01364)]\\\\n* **Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning**, arXiv 2023.03 [[Paper](https://arxiv.org/pdf/2303.15647)]\\\\n\\\\n#### Multimodal LLMs\\\\n\\\\n* **Vision-Language Instruction Tuning: A Review and Analysis**, arXiv 2023,11 [[Paper](https://arxiv.org/abs/2311.08172)] [[GitHub](https://github.com/palchenli/VL-Instruction-Tuning)]\\\\n* **Large Language Models Meet Computer Vision: A Brief Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.16673)]\\\\n* **Foundational Models Defining a New Era in Vision: A Survey and Outlook**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.13721)] [[GitHub](https://github.com/awaisrauf/Awesome-CV-Foundational-Models)]\\\\n* **Video Understanding with Large Language Models: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.17432)] [[GitHub](https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding)]\\\\n* **Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.10196)] [[GitHub](https://github.com/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM)]\\\\n* **Sparks of large audio models: A survey and outlook**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.12792)] [[GitHub](https://github.com/EmulationAI/awesome-large-audio-models)]\\\\n* **How to Bridge the Gap between Modalities: A Comprehensive Survey on Multimodal Large Language Model**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.07594)]\\\\n* **A Survey on Multimodal Large Language Models**, arXiv 2023.06 [[Paper](https://arxiv.org/abs/2306.13549)]\\\\n* **Multimodal Large Language Models: A Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.13165)]\\\\n\\\\n#### Knowledge Based LLMs\\\\n\\\\n###### Retrieval-Augmented LLMs\\\\n\\\\n* **Building trust in conversational ai: A comprehensive review and solution architecture for explainable, privacy-aware systems using llms and knowledge graph**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.13534)]\\\\n* **A Survey on Retrieval-Augmented Text Generation**, arXiv 2022.02 [[Paper](https://arxiv.org/abs/2202.01110)]\\\\n* **Retrieval-Augmented Generation for Large Language Models: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.10997)] [[GitHub](https://github.com/Tongji-KGLLM/RAG-Survey)]\\\\n\\\\n###### Knowledge Editing\\\\n\\\\n* **Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.05876)]\\\\n* **Knowledge Editing for Large Language Models: A Survey**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.16218)]\\\\n* **Editing Large Language Models: Problems, Methods, and Opportunities**, arXiv 2023.05 [[Paper](https://arxiv.org/abs/2305.13172)]\\\\n\\\\n#### Extension of LLMs\\\\n\\\\n###### LLMs with\\xa0Tools\\\\n\\\\n* **A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond**, arXiv 2024.03 [[Paper](https://arxiv.org/abs/2403.14734)] [[GitHub](https://github.com/QiushiSun/NCISurvey)]\\\\n* **Foundation Models for Decision Making: Problems, Methods, and Opportunities**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.04129)]\\\\n* **Augmented Language Models: a Survey**, arXiv 2023.02 [[Paper](https://arxiv.org/abs/2302.07842)]\\\\n* **Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.17903)] [[GitHub](https://github.com/yueyueL/ReliableLM4Code)]\\\\n* **Large Language Models Meet NL2Code: A Survey**, arXiv 2022.12 [[Paper](https://arxiv.org/abs/2212.09420)]\\\\n\\\\n###### LLMs and\\xa0Interactions\\\\n\\\\n* **Large Language Models for Robotics: A Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.07226)]\\\\n* **A Survey on Multimodal Large Language Models for Autonomous Driving**, WACV workshop 2023.11 [[Paper](https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/papers/Cui_A_Survey_on_Multimodal_Large_Language_Models_for_Autonomous_Driving_WACVW_2024_paper.pdf)]\\\\n* **LLM4Drive: A Survey of Large Language Models for Autonomous Driving**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.01043v3)] [[GitHub](https://github.com/Thinklab-SJTU/Awesome-LLM4AD)]\\\\n* **A Survey on Large Language Model based Autonomous Agents**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.11432)] [[GitHub](https://github.com/Paitesanshi/LLM-Agent-Survey)]\\\\n* **The Rise and Potential of Large Language Model Based Agents: A Survey**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.07864)] [[GitHub](https://github.com/WooooDyy/LLM-Agent-Paper-List)]\\\\n* **Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.11970)]\\\\n* **Large Multimodal Agents: A Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.15116)] [[GitHub](https://github.com/jun0wanan/awesome-large-multimodal-agents)]\\\\n* **Role play with large language models**, arXiv 2023.11 [[Paper](https://www.nature.com/articles/s41586-023-06647-8)]\\\\n\\\\n#### Long Sequence LLMs\\\\n\\\\n* **Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.12351)]\\\\n* **Length Extrapolation of Transformers: A Survey from the Perspective of Position Encoding**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.17044)]\\\\n\\\\n#### LLMs Applications\\\\n\\\\n###### Education\\\\n\\\\n* **ChatGPT and Beyond: The Generative AI Revolution in Education**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.15198)]\\\\n* **ChatGPT and large language models in academia: opportunities and challenges**, arXiv 2023.07 [[Paper](https://link.springer.com/article/10.1186/s13040-023-00339-9)]\\\\n* **ChatGPT for good? On opportunities and challenges of large language models for education**, arXiv 2023.04 [[Paper](https://www.sciencedirect.com/science/article/abs/pii/S1041608023000195)]\\\\n\\\\n###### Law\\\\n\\\\n* **Large Language Models in Law: A Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2312.03718)]\\\\n* **A short survey of viewing large language models in legal aspect**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.09136)]\\\\n\\\\n###### Healthcare\\\\n\\\\n* **A Survey of Large Language Models in Medicine: Progress, Application, and Challenge**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.05112)] [[GitHub](https://github.com/AI-in-Health/MedLLMsPracticalGuide)]\\\\n* **Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.01918)] [[GitHub](https://github.com/mingze-yuan/Awesome-LLM-Healthcare)]\\\\n* **Large AI Models in Health Informatics: Applications, Challenges, and the Future**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.11568)] [[GitHub](https://github.com/Jianing-Qiu/Awesome-Healthcare-Foundation-Models)]\\\\n* **A SWOT (Strengths, Weaknesses, Opportunities, and Threats) Analysis of ChatGPT in the Medical Literature: Concise Review**, JMIR 2023.11 [[Paper](https://www.jmir.org/2023/1/e49368/)]\\\\n* **ChatGPT in Healthcare: A Taxonomy and Systematic Review**, Computer Methods and Programs in Biomedicine 2024.01 [[Paper](https://www.sciencedirect.com/science/article/pii/S0169260724000087)]\\\\n* **A review of the explainability and safety of conversational agents for mental health to identify avenues for improvement**, NCBI 2023.10 [[Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10601652/)]\\\\n* **Towards a Psychological Generalist AI: A Survey of Current Applications of Large Language Models and Future Prospects**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.04578)]\\\\n* **Large Language Models in Mental Health Care: a Scoping Review**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.02984)]\\\\n* **The utility of ChatGPT as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and**, arXiv 2023.12 [[Paper](https://www.medrxiv.org/content/10.1101/2023.02.19.23286155v1)]\\\\n* **The imperative for regulatory oversight of large language models (or generative AI) in healthcare**, arXiv 2023.07 [[Paper](https://www.nature.com/articles/s41746-023-00873-0)]\\\\n* **A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.05694)] [[GitHub](https://github.com/KaiHe-better/LLM-for-Healthcare)]\\\\n* **The Shaky Foundations of Clinical Foundation Models: A Survey of Large Language Models and Foundation Models for EMRs**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.12961)]\\\\n\\\\n###### Games\\\\n\\\\n* **Large Language Models and Games: A Survey and Roadmap**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.18659)]\\\\n* **Large Language Models and Video Games: A Preliminary Scoping Review**, arXiv 2024.03 [[Paper](https://arxiv.org/abs/2403.02613)]\\\\n\\\\n###### NLP Tasks\\\\n\\\\n* **Large Language Models for Information Retrieval: A Survey**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.07107)] [[GitHub](https://github.com/RUC-NLPIR/LLM4IR-Survey)]\\\\n* **Large Language Models for Generative Information Extraction: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.17617)] [[GitHub](https://github.com/quqxui/Awesome-LLM4IE-Papers)]\\\\n* **Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey**, arXiv 2021.11 [[Paper](https://arxiv.org/abs/2111.01243)]\\\\n* **If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.00812)]\\\\n\\\\n###### Software Engineering\\\\n\\\\n* **Large Language Models for Software Engineering: Survey and Open Problems**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.03533)]\\\\n* **Large Language Models for Software Engineering: A Systematic Literature Review**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.10620)]\\\\n* **Software Testing with Large Language Models: Survey, Landscape, and Vision**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.07221)]\\\\n* **Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2311.07989)] [[GitHub](https://github.com/codefuse-ai/Awesome-Code-LLM)]\\\\n\\\\n###### Recommender Systems\\\\n\\\\n* **Foundation Models for Recommender Systems: A Survey and New Perspectives**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.11143)]\\\\n* **User Modeling in the Era of Large Language Models: Current Research and Future Directions**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2312.11518)] [[GitHub](https://github.com/TamSiuhin/LLM-UM-Reading)]\\\\n* **A Survey on Large Language Models for Personalized and Explainable Recommendations**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.12338)]\\\\n* **Large Language Models for Generative Recommendation: A Survey and Visionary Discussions**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.01157)]\\\\n* **A Survey on Large Language Models for Recommendation**, arXiv 2023.05 [[Paper](https://arxiv.org/abs/2305.19860)] [[GitHub](https://github.com/WLiK/LLM4Rec)]\\\\n* **How Can Recommender Systems Benefit from Large Language Models: A Survey**, arXiv 2023.06 [[Paper](https://arxiv.org/abs/2306.05817)] [[GitHub](https://github.com/CHIANGEL/Awesome-LLM-for-RecSys/)]\\\\n\\\\n* **A Survey of Graph Meets Large Language Model: Progress and Future Directions**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.12399)]\\\\n* **Large Language Models on Graphs: A Comprehensive Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.02783)] [[GitHub](https://github.com/PeterGriffinJin/Awesome-Language-Model-on-Graphs)]\\\\n* **The Contribution of Knowledge in Visiolinguistic Learning: A Survey on Tasks and Challenges**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.02411)]\\\\n\\\\n* **Large Language Models in Finance: A Survey**, ICAIF 2023.11 [[Paper](https://dl.acm.org/doi/10.1145/3604237.3626869)]\\\\n* **Mathematical Language Models: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.07622)]\\\\n* **Recent applications of AI to environmental disciplines: A review**, SCI TOTAL ENVIRON 2023.10 [[Paper](https://www.sciencedirect.com/science/article/pii/S0048969723063325?casa_token=sbh1pxIYyAgAAAAA:f3WytHabl8udc5v8OhRunnwHEemEAwNafzAcP2reVdGKMAJ-4EcJIxwKO4gdE8ozb6ZibbcY2_4)]\\\\n* **Opportunities and Challenges of Applying Large Language Models in Building Energy Efficiency and Decarbonization Studies: An Exploratory Overview**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.11701)]\\\\n* **When Large Language Models Meet Citation: A Survey**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.09727)]\\\\n* **A Survey of Text Watermarking in the Era of Large Language Models**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.07913)]\\\\n* **The future of gpt: A taxonomy of existing chatgpt research, current challenges, and possible future directions**, SSRN 2023.04 [[Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4413921)]\\\\n* **Summary of ChatGPT-Related Research and Perspective Towards the Future of Large Language Models**, Meta-Radiology 2023.09 [[Paper](https://www.sciencedirect.com/science/article/pii/S2950162823000176)]\\\\n\\\\nWe would like to thank the people who have contributed to this project. The core contributors are\\\\n\\\\n*Junhao Ruan, Long Meng, Weiqiao Shan, Tong Xiao, Jingbo Zhu*\\\\n\\\\n## About\\\\n\\\\nA collection of 150+ surveys on LLMs\\\\n\\\\n### Resources\\\\n\\\\n### License\\\\n\\\\n[CC0-1.0 license](#CC0-1.0-1-ov-file)\\\\n\\\\n### Uh oh!\\\\n\\\\nThere was an error while loading. Please reload this page.\\\\n\\\\n[Custom properties](/NiuTrans/ABigSurveyOfLLMs/custom-properties)\\\\n\\\\n### Stars\\\\n\\\\n[**342** stars](/NiuTrans/ABigSurveyOfLLMs/stargazers)\\\\n\\\\n### Watchers\\\\n\\\\n[**6** watching](/NiuTrans/ABigSurveyOfLLMs/watchers)\\\\n\\\\n### Forks\\\\n\\\\n[**26** forks](/NiuTrans/ABigSurveyOfLLMs/forks)\\\\n\\\\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FNiuTrans%2FABigSurveyOfLLMs&report=NiuTrans+%28user%29)\\\\n\\\\n## [Releases](/NiuTrans/ABigSurveyOfLLMs/releases)\\\\n\\\\nNo releases published\\\\n\\\\n## [Packages 0](/orgs/NiuTrans/packages?repo_name=ABigSurveyOfLLMs)\\\\n\\\\nNo packages published\\\\n\\\\n## [Contributors 4](/NiuTrans/ABigSurveyOfLLMs/graphs/contributors)\\\\n\\\\n### Uh oh!\\\\n\\\\nThere was an error while loading. Please reload this page.\\\\n\\\\nYou can’t perform that action at this time.\\\\n\\\\n \"}], \"response_time\": 5.95, \"request_id\": \"de73280e-685d-4cb6-b1c5-396e93aef7ca\"}', name='tavily_search', id='29a23fb9-de0d-4b9d-9cdf-ad6d3fe16a4b', tool_call_id='call_afJIDcLuyfzldcrw3r6CqXzC')]}}\n",
      "{'agent': {'messages': [AIMessage(content='LLM(대규모 언어 모델)에 대한 최근 연구와 발전을 다룬 여러 논문들을 다음과 같이 요약할 수 있습니다:\\n\\n1. **A Survey of Large Language Models** ([Link to Paper](https://arxiv.org/abs/2303.18223)):\\n   - 이 논문은 LLM의 배경, 주요 발견 및 최신 기술을 소개합니다. LLM은 사전 훈련, 파라미터 조정, 활용 및 평가와 같은 네 가지 주요 측면에 집중하여, 모델의 규모가 성능 향상에 어떻게 기여하는지를 설명합니다. ChatGPT 등 LLM의 발전이 AI 커뮤니티에 미치는 영향을 논의하며, LLM 개발에 필요한 자원과 향후 방향에 대해서도 언급합니다.\\n\\n2. **Employing Large Language Models in Survey Research** ([Link to Article](https://www.sciencedirect.com/science/article/pii/S2949719123000171)):\\n   - 이 기사에서는 LLM이 설문 조사 연구에 어떻게 활용될 수 있는지를 다룹니다. LLM은 질문 작성 및 응답 편향 문제를 해결하는 데 도움을 줄 수 있지만, 샘플링 편향이나 비응답 편향은 해결하지 못하는 한계를 가지고 있습니다. LLM은 다른 방법과 함께 사용될 때 그 유용성을 극대화할 수 있습니다.\\n\\n3. **NiuTrans/ABigSurveyOfLLMs** ([GitHub Repository](https://github.com/NiuTrans/ABigSurveyOfLLMs)):\\n   - 이 GitHub 저장소는 150개 이상의 LLM 관련 설문을 모은 컬렉션으로, LLM의 발전과 관련된 다양한 연구 결과를 제공합니다. 이 자료는 LLM에 대한 포괄적인 개요를 원하시는 분들에게 유용할 것입니다.\\n\\n이번 연구들은 LLM이 AI 분야에서 중요한 발전을 이루고 있음을 보여주며, 설문 조사나 다양한 연구 영역에서의 활용 가능성을 탐색하고 있습니다. LLM의 진화를 통해 AI 알고리즘 개발 방식이 혁신적으로 변화할 것으로 기대됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 447, 'prompt_tokens': 17009, 'total_tokens': 17456, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1920}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-Cqaq9mkRzwZfGE1DxQuDX71wTZmvj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5496-70f6-75a3-b4ab-1d4605b56559-0', usage_metadata={'input_tokens': 17009, 'output_tokens': 447, 'total_tokens': 17456, 'input_token_details': {'audio': 0, 'cache_read': 1920}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "{'summarize_messages': {'summary': '대화 기록 요약은 다음과 같습니다:\\n\\n1. 사용자가 \"LLM Survey\"에 대한 논문을 검색해 요약해 달라고 요청함.\\n2. AI는 처음에 arxiv에서 검색을 시도하였고, 사용자가 웹에서의 검색을 요청하자, tavily_search를 이용해 \"LLM Survey\"에 대한 정보를 검색함.\\n3. 검색 결과 세 가지 논문/자료가 요약됨:\\n   - **A Survey of Large Language Models**: LLM의 기술적 배경과 최신 발전, 성능 향상에 기여하는 요소들(사전 훈련, 활용 등)에 대해 설명.\\n   - **Employing Large Language Models in Survey Research**: LLM이 설문 조사에서의 잠재력을 다루며, 질문 작성 및 응답 편향 문제를 해결할 수 있지만 샘플링 편향은 해결하지 못한다고 언급.\\n   - **NiuTrans/ABigSurveyOfLLMs**: 150개 이상의 LLM 관련 설문을 모은 GitHub 저장소로, 이 분야에 대한 포괄적 개요를 제공.\\n\\n이 연구들은 LLM이 AI 분야에서 중요한 발전을 이루며, 설문 조사 및 다양한 연구 분야에서의 활용 가능성을 탐구하고 있음을 보여줌.'}}\n",
      "{'delete_messages': {'messages': [RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='b726fd8c-cb9b-4fbf-90bd-a3b993d9b363'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='lc_run--019b5496-0a1e-7e32-8c81-20819225b86d-0'), RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='b1d924ed-8166-4ba0-b048-933e1cae0ed8')]}}\n"
     ]
    }
   ],
   "source": [
    "for response in graph.stream(\n",
    "    Command(resume={\"action\": \"continue\"}),\n",
    "    config=config,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 1973, 'total_tokens': 1996, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1920}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_c4585b5b9c', 'id': 'chatcmpl-Cqapq1bDxKNE2P8XNVMW8Gb1WjWxD', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019b5496-276c-70c2-949e-9d532d5e9261-0', tool_calls=[{'name': 'tavily_search', 'args': {'query': 'LLM Survey', 'search_depth': 'advanced'}, 'id': 'call_afJIDcLuyfzldcrw3r6CqXzC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1973, 'output_tokens': 23, 'total_tokens': 1996, 'input_token_details': {'audio': 0, 'cache_read': 1920}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='{\"query\": \"LLM Survey\", \"follow_up_questions\": null, \"answer\": \"Large language models (LLMs) revolutionize AI development, with key advances in pre-training, adaptation, utilization, and evaluation. They assist in survey research by generating responses but cannot address sampling bias. A comprehensive survey collection exists, covering over 150 surveys on LLMs.\", \"images\": [{\"url\": \"https://pic1.zhimg.com/v2-b78c8a045bea1efdee800de108066cb0_r.jpg\", \"description\": \"The image compares in-context learning and chain-of-thought prompting with examples of mathematical reasoning questions, demonstrations, and test queries, illustrating their differences in approach.\"}, {\"url\": \"https://pic3.zhimg.com/v2-8be80510e165e6de7f8d657dfbd09516_r.jpg\", \"description\": \"A colorful circular diagram categorizes aspects of large language model evaluation, including knowledge and capability, alignment evaluation, safety, robustness evaluation, and specialized LLMs.\"}, {\"url\": \"https://gkwang-1251992353.cos.ap-shanghai.myqcloud.com/blog/post/llmsurvey/LLM_Survey_Corpus.png\", \"description\": \"The table lists various data sources used in an LLM survey, detailing their size, source type, and latest update times, with references highlighted in green.\"}, {\"url\": \"https://milanlproc.github.io/publication/2025-llm-survey-simulation/featured.png\", \"description\": \"The diagram illustrates a framework for Large Language Model (LLM) survey-based question answering, showing inputs from countries and multiple-choice questions, training processes involving human feedback and option distribution, and methods of inference including direct answer prediction and an alternative approach using unseen questions and countries.\"}, {\"url\": \"https://yellow-cdn.veclightyear.com/b66f4b6e/cf14b767-adef-48d7-83e7-6e6dcbb46f30.png\", \"description\": \"Various aspects of large language model evaluation, including knowledge and capability, alignment evaluation, safety, specialized LLM applications, and evaluation organization, are illustrated in a colorful circular diagram.\"}], \"results\": [{\"url\": \"https://arxiv.org/abs/2303.18223\", \"title\": \"[2303.18223] A Survey of Large Language Models\", \"content\": \"revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.\", \"score\": 0.798077, \"raw_content\": \"We gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors. [Donate](https://info.arxiv.org/about/donate.html)\\\\n\\\\n> [cs](/list/cs/recent) > arXiv:2303.18223\\\\n\\\\n\\\\n\\\\n# Computer Science > Computation and Language\\\\n\\\\n**arXiv:2303.18223** (cs)\\\\n\\\\n[Submitted on 31 Mar 2023 ([v1](https://arxiv.org/abs/2303.18223v1)), last revised 11 Mar 2025 (this version, v16)]\\\\n\\\\n# Title:A Survey of Large Language Models\\\\n\\\\nAuthors:[Wayne Xin Zhao](https://arxiv.org/search/cs?searchtype=author&query=Zhao,+W+X), [Kun Zhou](https://arxiv.org/search/cs?searchtype=author&query=Zhou,+K), [Junyi Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+J), [Tianyi Tang](https://arxiv.org/search/cs?searchtype=author&query=Tang,+T), [Xiaolei Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+X), [Yupeng Hou](https://arxiv.org/search/cs?searchtype=author&query=Hou,+Y), [Yingqian Min](https://arxiv.org/search/cs?searchtype=author&query=Min,+Y), [Beichen Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+B), [Junjie Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+J), [Zican Dong](https://arxiv.org/search/cs?searchtype=author&query=Dong,+Z), [Yifan Du](https://arxiv.org/search/cs?searchtype=author&query=Du,+Y), [Chen Yang](https://arxiv.org/search/cs?searchtype=author&query=Yang,+C), [Yushuo Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen,+Y), [Zhipeng Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen,+Z), [Jinhao Jiang](https://arxiv.org/search/cs?searchtype=author&query=Jiang,+J), [Ruiyang Ren](https://arxiv.org/search/cs?searchtype=author&query=Ren,+R), [Yifan Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+Y), [Xinyu Tang](https://arxiv.org/search/cs?searchtype=author&query=Tang,+X), [Zikang Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+Z), [Peiyu Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+P), [Jian-Yun Nie](https://arxiv.org/search/cs?searchtype=author&query=Nie,+J), [Ji-Rong Wen](https://arxiv.org/search/cs?searchtype=author&query=Wen,+J)\\\\n\\\\nView a PDF of the paper titled A Survey of Large Language Models, by Wayne Xin Zhao and 20 other authors\\\\n\\\\n[View PDF](/pdf/2303.18223) [HTML (experimental)](https://arxiv.org/html/2303.18223v16)\\\\n> Abstract:Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.\\\\n\\\\n|  |  |\\\\n| --- | --- |\\\\n| Comments: | ongoing work; 144 pages, 1081 citations |\\\\n| Subjects: | Computation and Language (cs.CL); Artificial Intelligence (cs.AI) |\\\\n| Cite as: | [arXiv:2303.18223](https://arxiv.org/abs/2303.18223) [cs.CL] |\\\\n|  | (or  [arXiv:2303.18223v16](https://arxiv.org/abs/2303.18223v16) [cs.CL] for this version) |\\\\n|  | <https://doi.org/10.48550/arXiv.2303.18223> arXiv-issued DOI via DataCite |\\\\n\\\\n## Submission history\\\\n\\\\nFrom: Kun Zhou [[view email](/show-email/281bf9f9/2303.18223)]   \\\\n **[[v1]](/abs/2303.18223v1)** Fri, 31 Mar 2023 17:28:46 UTC (991 KB)  \\\\n **[[v2]](/abs/2303.18223v2)** Sun, 9 Apr 2023 15:49:09 UTC (1,306 KB)  \\\\n **[[v3]](/abs/2303.18223v3)** Tue, 11 Apr 2023 16:20:17 UTC (1,305 KB)  \\\\n **[[v4]](/abs/2303.18223v4)** Wed, 12 Apr 2023 16:13:54 UTC (1,310 KB)  \\\\n **[[v5]](/abs/2303.18223v5)** Sun, 16 Apr 2023 16:42:37 UTC (1,678 KB)  \\\\n **[[v6]](/abs/2303.18223v6)** Mon, 24 Apr 2023 16:53:57 UTC (2,528 KB)  \\\\n **[[v7]](/abs/2303.18223v7)** Tue, 25 Apr 2023 14:42:36 UTC (2,528 KB)  \\\\n **[[v8]](/abs/2303.18223v8)** Thu, 27 Apr 2023 15:54:48 UTC (2,533 KB)  \\\\n **[[v9]](/abs/2303.18223v9)** Fri, 28 Apr 2023 15:39:09 UTC (2,534 KB)  \\\\n **[[v10]](/abs/2303.18223v10)** Sun, 7 May 2023 17:59:15 UTC (2,031 KB)  \\\\n **[[v11]](/abs/2303.18223v11)** Thu, 29 Jun 2023 16:09:05 UTC (4,226 KB)  \\\\n **[[v12]](/abs/2303.18223v12)** Mon, 11 Sep 2023 15:13:59 UTC (4,687 KB)  \\\\n **[[v13]](/abs/2303.18223v13)** Fri, 24 Nov 2023 13:57:45 UTC (6,600 KB)  \\\\n **[[v14]](/abs/2303.18223v14)** Tue, 24 Sep 2024 07:02:59 UTC (5,852 KB)  \\\\n **[[v15]](/abs/2303.18223v15)** Sun, 13 Oct 2024 06:11:31 UTC (5,852 KB)  \\\\n **[v16]** Tue, 11 Mar 2025 16:51:11 UTC (7,340 KB)\\\\n\\\\nFull-text links:\\\\n\\\\n## Access Paper:\\\\n\\\\nView a PDF of the paper titled A Survey of Large Language Models, by Wayne Xin Zhao and 20 other authors\\\\n\\\\n* [View PDF](/pdf/2303.18223)\\\\n* [HTML (experimental)](https://arxiv.org/html/2303.18223v16)\\\\n* [TeX Source](/src/2303.18223)\\\\n\\\\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/ \\\\\"Rights to this article\\\\\")\\\\n\\\\nCurrent browse context:\\\\n\\\\ncs.CL\\\\n\\\\n[<\\xa0prev](/prevnext?id=2303.18223&function=prev&context=cs.CL \\\\\"previous in cs.CL (accesskey p)\\\\\")  \\xa0 | \\xa0  [next\\xa0>](/prevnext?id=2303.18223&function=next&context=cs.CL \\\\\"next in cs.CL (accesskey n)\\\\\")\\\\n\\\\n[new](/list/cs.CL/new)  |  [recent](/list/cs.CL/recent)  | [2023-03](/list/cs.CL/2023-03)\\\\n\\\\nChange to browse by:\\\\n\\\\n[cs](/abs/2303.18223?context=cs)  \\\\n [cs.AI](/abs/2303.18223?context=cs.AI)\\\\n\\\\n### References & Citations\\\\n\\\\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2303.18223)\\\\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2303.18223)\\\\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2303.18223)\\\\n\\\\n### [1 blog link](/tb/2303.18223)\\\\n\\\\n([what is this?](https://info.arxiv.org/help/trackback.html))\\\\n\\\\nexport BibTeX citation Loading...\\\\n\\\\n## BibTeX formatted citation\\\\n\\\\n×\\\\n\\\\nData provided by:\\\\n\\\\n### Bookmark\\\\n\\\\n# Bibliographic and Citation Tools\\\\n\\\\nBibliographic Explorer *([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\\\\n\\\\nConnected Papers *([What is Connected Papers?](https://www.connectedpapers.com/about))*\\\\n\\\\nLitmaps *([What is Litmaps?](https://www.litmaps.co/))*\\\\n\\\\nscite Smart Citations *([What are Smart Citations?](https://www.scite.ai/))*\\\\n\\\\n# Code, Data and Media Associated with this Article\\\\n\\\\nalphaXiv *([What is alphaXiv?](https://alphaxiv.org/))*\\\\n\\\\nCatalyzeX Code Finder for Papers *([What is CatalyzeX?](https://www.catalyzex.com))*\\\\n\\\\nDagsHub *([What is DagsHub?](https://dagshub.com/))*\\\\n\\\\nGotit.pub *([What is GotitPub?](http://gotit.pub/faq))*\\\\n\\\\nHugging Face *([What is Huggingface?](https://huggingface.co/huggingface))*\\\\n\\\\nPapers with Code *([What is Papers with Code?](https://paperswithcode.com/))*\\\\n\\\\nScienceCast *([What is ScienceCast?](https://sciencecast.org/welcome))*\\\\n\\\\n# Demos\\\\n\\\\nReplicate *([What is Replicate?](https://replicate.com/docs/arxiv/about))*\\\\n\\\\nHugging Face Spaces *([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\\\\n\\\\nTXYZ.AI *([What is TXYZ.AI?](https://txyz.ai))*\\\\n\\\\n# Recommenders and Search Tools\\\\n\\\\nInfluence Flower *([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\\\\n\\\\nCORE Recommender *([What is CORE?](https://core.ac.uk/services/recommender))*\\\\n\\\\n* Author\\\\n* Venue\\\\n* Institution\\\\n* Topic\\\\n\\\\n# arXivLabs: experimental projects with community collaborators\\\\n\\\\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\\\\n\\\\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\\\\n\\\\nHave an idea for a project that will add value for arXiv\\'s community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\\\\n\\\\n[Which authors of this paper are endorsers?](/auth/show-endorsers/2303.18223) | [Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html))\"}, {\"url\": \"https://www.sciencedirect.com/science/article/pii/S2949719123000171\", \"title\": \"Employing large language models in survey research - ScienceDirect\", \"content\": \"This article discusses the promising potential of employing large language models (LLMs) for survey research, including generating responses to survey items. LLMs can address some of the challenges associated with survey research regarding question-wording and response bias. They can address issues relating to a lack of clarity and understanding but cannot yet correct for sampling or nonresponse bias challenges. While LLMs can assist with some of the challenges with survey research, at present,\", \"score\": 0.7672197, \"raw_content\": \"[Skip to article](#screen-reader-main-title)\\\\n\\\\n\\\\n[My account](/user/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS2949719123000171&from=globalheader)\\\\n\\\\n[Sign in](/user/institution/login?targetURL=%2Fscience%2Farticle%2Fpii%2FS2949719123000171)\\\\n\\\\n* View\\xa0**PDF**\\\\n\\\\n## [Natural Language Processing Journal](/journal/natural-language-processing-journal \\\\\"Go to Natural Language Processing Journal on ScienceDirect\\\\\")\\\\n\\\\n[Volume 4](/journal/natural-language-processing-journal/vol/4/suppl/C \\\\\"Go to table of contents for this volume/issue\\\\\"), September 2023, 100020\\\\n\\\\n# Employing large language models in survey research\\\\n\\\\nAuthor links open overlay panel, ,\\\\n\\\\n[https://doi.org/10.1016/j.nlp.2023.100020](https://doi.org/10.1016/j.nlp.2023.100020 \\\\\"Persistent link using digital object identifier\\\\\")[Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=S2949719123000171&orderBeanReset=true)\\\\n\\\\nUnder a Creative Commons [license](http://creativecommons.org/licenses/by/4.0/)\\\\n\\\\nOpen access\\\\n\\\\n## Abstract\\\\n\\\\nThis article discusses the promising potential of employing large language models (LLMs) for survey research, including generating responses to survey items. LLMs can address some of the challenges associated with survey research regarding question-wording and response bias. They can address issues relating to a lack of clarity and understanding but cannot yet correct for sampling or nonresponse bias challenges. While LLMs can assist with some of the challenges with survey research, at present, LLMs need to be used in conjunction with other methods and approaches. With thoughtful and nuanced approaches to development, LLMs can be used responsibly and beneficially while minimizing the associated risks.\\\\n\\\\n\\\\n\\\\n## Keywords\\\\n\\\\nSurvey research\\\\n\\\\nLarge language models\\\\n\\\\nSurvey data\\\\n\\\\nSurveys\\\\n\\\\nLLM survey respondents\\\\n\\\\n## Cited by (0)\\\\n\\\\n© 2023 The Author(s). Published by Elsevier B.V.\\\\n\\\\n \"}, {\"url\": \"https://github.com/NiuTrans/ABigSurveyOfLLMs\", \"title\": \"NiuTrans/ABigSurveyOfLLMs: A collection of 150+ surveys on LLMs\", \"content\": \"Large language models (LLMs) are making sweeping advances across many fields of artificial intelligence. As a result, research interest and progress in LLMs have exploded. There are now hundreds of research papers on LLMs published in various conferences or posted to open-access archives every day. Given the significant growth in LLM-related papers, this work compiles surveys on LLMs to provide a comprehensive overview of the field. Most of these surveys have been published or posted in the [...] Security and Privacy Challenges of Large Language Models: A Survey, arXiv 2024.01 [Paper]\\\\n Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks, arXiv 2023.10 [Paper]\\\\n A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly, arXiv 2023.12 [Paper]\\\\n Tricking LLMs into Disobedience: Formalizing, Analyzing, and Detecting Jailbreaks, arXiv 2023.05 [Paper] [...] | Name | Name | Last commit message | Last commit date |\\\\n ---  --- |\\\\n| Latest commit   History25 Commits |\\\\n| LICENSE | LICENSE |  |  |\\\\n| README.md | README.md |  |  |\\\\n|  |\\\\n\\\\n## Repository files navigation\\\\n\\\\n# A Survey of LLM Surveys\", \"score\": 0.73846215, \"raw_content\": \"[Skip to content](#start-of-content)   \\\\n\\\\n\\\\n\\\\n## Navigation Menu\\\\n\\\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FNiuTrans%2FABigSurveyOfLLMs) \\\\n\\\\nAppearance settings\\\\n\\\\n# Search code, repositories, users, issues, pull requests...\\\\n\\\\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\\\\n\\\\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FNiuTrans%2FABigSurveyOfLLMs)\\\\n\\\\n [Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=NiuTrans%2FABigSurveyOfLLMs) \\\\n\\\\nAppearance settings\\\\n\\\\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\\\\n\\\\n{{ message }}\\\\n\\\\n[NiuTrans](/NiuTrans)   /  **[ABigSurveyOfLLMs](/NiuTrans/ABigSurveyOfLLMs)**  Public\\\\n\\\\n* [Notifications](/login?return_to=%2FNiuTrans%2FABigSurveyOfLLMs)  You must be signed in to change notification settings\\\\n* [Fork 26](/login?return_to=%2FNiuTrans%2FABigSurveyOfLLMs)\\\\n* [Star  342](/login?return_to=%2FNiuTrans%2FABigSurveyOfLLMs)\\\\n\\\\nA collection of 150+ surveys on LLMs\\\\n\\\\n### License\\\\n\\\\n[CC0-1.0 license](/NiuTrans/ABigSurveyOfLLMs/blob/main/LICENSE)\\\\n\\\\n[342 stars](/NiuTrans/ABigSurveyOfLLMs/stargazers)   [26 forks](/NiuTrans/ABigSurveyOfLLMs/forks)   [Branches](/NiuTrans/ABigSurveyOfLLMs/branches)   [Tags](/NiuTrans/ABigSurveyOfLLMs/tags)   [Activity](/NiuTrans/ABigSurveyOfLLMs/activity)\\\\n\\\\n[Star](/login?return_to=%2FNiuTrans%2FABigSurveyOfLLMs)\\\\n\\\\n[Notifications](/login?return_to=%2FNiuTrans%2FABigSurveyOfLLMs)  You must be signed in to change notification settings\\\\n\\\\n# NiuTrans/ABigSurveyOfLLMs\\\\n\\\\n[Branches](/NiuTrans/ABigSurveyOfLLMs/branches)[Tags](/NiuTrans/ABigSurveyOfLLMs/tags)\\\\n\\\\nOpen more actions menu\\\\n\\\\n## Folders and files\\\\n\\\\n| Name | Name | Last commit message | Last commit date |\\\\n| --- | --- | --- | --- |\\\\n| Latest commit   History[25 Commits](/NiuTrans/ABigSurveyOfLLMs/commits/main/) |\\\\n| [LICENSE](/NiuTrans/ABigSurveyOfLLMs/blob/main/LICENSE \\\\\"LICENSE\\\\\") | [LICENSE](/NiuTrans/ABigSurveyOfLLMs/blob/main/LICENSE \\\\\"LICENSE\\\\\") |  |  |\\\\n| [README.md](/NiuTrans/ABigSurveyOfLLMs/blob/main/README.md \\\\\"README.md\\\\\") | [README.md](/NiuTrans/ABigSurveyOfLLMs/blob/main/README.md \\\\\"README.md\\\\\") |  |  |\\\\n|  |\\\\n\\\\n## Repository files navigation\\\\n\\\\n# A Survey of LLM Surveys\\\\n\\\\nLarge language models (LLMs) are making sweeping advances across many fields of artificial intelligence. As a result, research interest and progress in LLMs have exploded. There are now hundreds of research papers on LLMs published in various conferences or posted to open-access archives every day. Given the significant growth in LLM-related papers, this work compiles surveys on LLMs to provide a comprehensive overview of the field. Most of these surveys have been published or posted in the past few years, so this collection is relatively new. We hope that our compilation can be helpful for people who want to get a quick understanding of the field.\\\\n\\\\n## Outline\\\\n\\\\n* [General Surveys](#section1)\\\\n* [Transformers](#section2)\\\\n* [Alignment](#section3)\\\\n* [Prompt Learning](#section4)\\\\n  + [In-context Learning](#section5)\\\\n  + [Chain of Thought](#section6)\\\\n  + [Prompt Engineering](#section7)\\\\n  + [Reasoning](#section8)\\\\n* [Data](#section9)\\\\n* [Evaluation](#section10)\\\\n* [Societal Issues](#section11)\\\\n* [Safety](#section12)\\\\n  + [Source Detection](#section13)\\\\n  + [Security](#section14)\\\\n* [Misinformation](#section15)\\\\n  + [Hallucinations](#section16)\\\\n  + [Factuality](#section17)\\\\n* [Attributes of LLMs](#section18)\\\\n* [Efficient LLMs](#section19)\\\\n* [Learning Methods\\xa0for LLMs](#section20)\\\\n* [Multimodal LLMs](#section21)\\\\n* [Knowledge Based LLMs](#section22)\\\\n  + [Retrieval-Augmented LLMs](#section23)\\\\n  + [Knowledge Editing](#section24)\\\\n* [Extension of LLMs](#section25)\\\\n  + [LLMs with\\xa0Tools](#section26)\\\\n  + [LLMs and\\xa0Interactions](#section27)\\\\n* [Long Sequence LLMs](#section28)\\\\n* [LLMs Applications](#section29)\\\\n  + [Education](#section30)\\\\n  + [Law](#section31)\\\\n  + [Healthcare](#section32)\\\\n  + [Games](#section33)\\\\n  + [NLP Tasks](#section34)\\\\n  + [Software Engineering](#section35)\\\\n  + [Recommender Systems](#section36)\\\\n  + [Graphs](#section37)\\\\n  + [Other](#section38)\\\\n\\\\n## Survey List\\\\n\\\\n#### General Surveys\\\\n\\\\n* **Large Language Models: A Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.06196)]\\\\n* **A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.04226)]\\\\n* **A Survey of Large Language Models**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2303.18223)] [[GitHub](https://github.com/RUCAIBox/LLMSurvey)]\\\\n* **Foundations of Large Language Models**, arXiv 2025.01 [[paper](https://arxiv.org/abs/2501.09223)]\\\\n* **Challenges and Applications of Large Language Models**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.10169)]\\\\n* **Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond**, arXiv 2023.04 [[Paper](https://arxiv.org/abs/2304.13712)] [[GitHub](https://github.com/Mooler0410/LLMsPracticalGuide)]\\\\n* **A Survey on Large Language Models: Applications, Challenges, Limitations, and Practical Usage**, TechRxiv 2023.07 [[Paper](https://www.techrxiv.org/doi/full/10.36227/techrxiv.23589741.v1)] [[GitHub](https://github.com/anas-zafar/LLM-Survey)]\\\\n* **A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT**, arXiv 2023.05 [[Paper](https://arxiv.org/abs/2302.09419)]\\\\n* **A Comprehensive Overview of Large Language Models**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.06435v8)] [[GitHub](https://github.com/humza909/LLM_Survey)]\\\\n* **Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing**, ACM Computing Surveys 2023.01 [[Paper](https://dl.acm.org/doi/full/10.1145/3560815)]\\\\n\\\\n#### Transformers\\\\n\\\\n* **A survey of transformers**, arXiv 2022.10 [[Paper](https://www.sciencedirect.com/science/article/pii/S2666651022000146)]\\\\n* **Introduction to Transformers: an NLP Perspective**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.17633)] [[GitHub](https://github.com/NiuTrans/Introduction-to-Transformers)]\\\\n* **Efficient Transformers: A Survey**, arXiv 2022.12 [[Paper](https://dl.acm.org/doi/full/10.1145/3530811)]\\\\n* **A Practical Survey on Faster and Lighter Transformers**, arXiv 2023.07 [[Paper](https://dl.acm.org/doi/abs/10.1145/3586074)]\\\\n* **Attention Mechanism, Transformers, BERT, and GPT: Tutorial and Survey**, arXiv 2020.12 [[Paper](https://osf.io/preprints/osf/m6gcn)]\\\\n\\\\n#### Alignment\\\\n\\\\n* **Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation**, arXiv 2023.06 [[Paper](https://arxiv.org/abs/2305.00955)]\\\\n* **AI Alignment: A Comprehensive Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2310.19852)]\\\\n* **Large Language Model Alignment: A Survey**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.15025)]\\\\n* **From Instructions to Intrinsic Human Values -- A Survey of Alignment Goals for Big Models**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2308.12014)] [[GitHub](https://github.com/ValueCompass/Alignment-Goal-Survey)]\\\\n* **Aligning Large Language Models with Human: A Survey**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.12966)] [[GitHub](https://github.com/GaryYufei/AlignLLMHumanSurvey)]\\\\n* **Instruction Tuning for Large Language Models: A Survey**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.10792)]\\\\n* **A Comprehensive Survey on Instruction Following**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2303.10475v7)] [[GitHub](https://github.com/RenzeLou/awesome-instruction-learning)]\\\\n\\\\n#### Prompt Learning\\\\n\\\\n###### In-context Learning\\\\n\\\\n* **A Practical Survey on Zero-shot Prompt Design for In-context Learning**, ranlp 2023.09 [[Paper](https://aclanthology.org/2023.ranlp-1.69/)]\\\\n* **A Survey on In-context Learning**, arXiv 2023.06 [[Paper](https://arxiv.org/abs/2301.00234)]\\\\n\\\\n###### Chain of Thought\\\\n\\\\n* **A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2309.15402)] [[GitHub](https://github.com/zchuz/CoT-Reasoning-Survey)]\\\\n* **Towards Better Chain-of-Thought Prompting Strategies: A Survey**, arXiv 2023.10 [[Paper](https://doi.org/10.48550/arXiv.2310.04959)]\\\\n* **Igniting Language Intelligence: The Hitchhiker\\'s Guide From Chain-of-Thought Reasoning to Language Agents**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.11797)] [[GitHub](https://github.com/Zoeyyao27/CoT-Igniting-Agent)]\\\\n\\\\n###### Prompt Engineering\\\\n\\\\n* **Prompting Frameworks for Large Language Models: A Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.12785)] [[GitHub](https://github.com/lxx0628/Prompting-Framework-Survey)]\\\\n* **Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.14735)]\\\\n\\\\n###### Reasoning\\\\n\\\\n* **Towards Reasoning in Large Language Models: A Survey**, arXiv 2022.12 [[Paper](https://arxiv.org/abs/2212.10403)] [[GitHub](https://github.com/jeffhj/LM-reasoning)]\\\\n* **A Survey of Reasoning with Foundation Models**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.11562)] [[GitHub](https://github.com/reasoning-survey/Awesome-Reasoning-Foundation-Models)]\\\\n\\\\n#### Data\\\\n\\\\n* **Data Management For Large Language Models: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.01700)] [[GitHub](https://github.com/ZigeW/data_management_LLM)]\\\\n* **A Survey on Data Selection for Language Models**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.16827)]\\\\n* **Datasets for Large Language Models: A Comprehensive Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.18041)] [[GitHub](https://github.com/lmmlzn/Awesome-LLMs-Datasets)]\\\\n* **Large Language Models for Data Annotation: A Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.13446)] [[GitHub](https://github.com/Zhen-Tan-dmml/LLM4Annotation)]\\\\n* **A Survey on Data Selection for LLM Instruction Tuning**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.05123)]\\\\n* **A Survey on Knowledge Distillation of Large Language Models**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.13116)]\\\\n\\\\n#### Evaluation\\\\n\\\\n* **Evaluating Large Language Models: A Comprehensive Survey**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.19736)] [[GitHub](https://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers)]\\\\n* **A Survey on Evaluation of Large Language Models**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.03109)] [[GitHub](https://github.com/MLGroupJLU/LLM-eval-survey)]\\\\n* **Baby steps in evaluating the capacities of large language models**, arXiv 2023.06 [[Paper](https://www.nature.com/articles/s44159-023-00211-x)]\\\\n\\\\n#### Societal Issues\\\\n\\\\n* **A Survey on Fairness in Large Language Models**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.10149)]\\\\n* **Large Language Models as Subpopulation Representative Models: A Review**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.17888)]\\\\n* **Perception, performance, and detectability of conversational artificial intelligence across 32 university courses**, SCI REP-UK 2023.08 [[Paper](https://www.nature.com/articles/s41598-023-38964-3)]\\\\n* **Should chatgpt be biased? challenges and risks of bias in large language models**, arXiv 2023.04 [[Paper](https://arxiv.org/abs/2304.03738)]\\\\n* **Bias and Fairness in Large Language Models: A Survey**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.00770)] [[GitHub](https://github.com/i-gallegos/Fair-LLM-Benchmark)]\\\\n\\\\n#### Safety\\\\n\\\\n###### Source Detection\\\\n\\\\n* **A Survey on Detection of LLMs-Generated Content**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.15654)] [[GitHub](https://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection)]\\\\n* **A Survey on LLM-generated Text Detection: Necessity, Methods, and Future Directions**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.14724)] [[GitHub](https://github.com/NLP2CT/LLM-generated-Text-Detection)]\\\\n* **Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated Text**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.07689)]\\\\n* **The Science of Detecting LLM-Generated Texts**, arXiv 2023.02 [[Paper](https://arxiv.org/abs/2303.07205)]\\\\n\\\\n###### Security\\\\n\\\\n* **Security and Privacy Challenges of Large Language Models: A Survey**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2402.00888)]\\\\n* **Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.10844)]\\\\n* **A Survey on Large Language Model (LLM) Security and Privacy: The Good, the Bad, and the Ugly**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.02003)]\\\\n* **Tricking LLMs into Disobedience: Formalizing, Analyzing, and Detecting Jailbreaks**, arXiv 2023.05 [[Paper](https://arxiv.org/abs/2305.14965)]\\\\n* **A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation**, arXiv 2023.05 [[Paper](https://arxiv.org/abs/2305.11391)]\\\\n\\\\n#### Misinformation\\\\n\\\\n###### Hallucinations\\\\n\\\\n* **Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.07914)]\\\\n* **A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.05232)] [[GitHub](https://github.com/LuckyyySTA/Awesome-LLM-hallucination)]\\\\n* **A Survey of Hallucination in “Large” Foundation Models**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.05922)] [[GitHub](https://github.com/vr25/hallucination-foundation-model-survey)]\\\\n* **Siren\\'s Song in the AI Ocean: A Survey on Hallucination in Large Language Models**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.01219)] [[GitHub](https://github.com/HillZhang1999/llm-hallucination-survey)]\\\\n* **Cognitive Mirage: A Review of Hallucinations in Large Language Models**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.06794)] [[GitHub](https://github.com/hongbinye/Cognitive-Mirage-Hallucinations-in-LLMs)]\\\\n* **Augmenting LLMs with Knowledge: A survey on hallucination prevention**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.16459)]\\\\n* **A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.01313)]\\\\n\\\\n###### Factuality\\\\n\\\\n* **Trustworthy LLMs: a Survey and Guideline for Evaluating Large Language Models\\' Alignment**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.05374)]\\\\n* **Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.07521)] [[GitHub](https://github.com/wangcunxiang/LLM-Factuality-Survey)]\\\\n* **Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.16570)]\\\\n\\\\n#### Attributes of LLMs\\\\n\\\\n* **Explainability for Large Language Models: A Survey**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.01029)]\\\\n* **The Mystery and Fascination of LLMs: A Comprehensive Survey on the Interpretation and Analysis of Emergent Abilitie**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.00237)]\\\\n* **From Understanding to Utilization: A Survey on Explainability for Large Language Models**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.12874)]\\\\n* **A Survey of Large Language Models Attribution**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.03731)] [[GitHub](https://github.com/HITsz-TMG/awesome-llm-attributions)]\\\\n* **A Survey of Language Model Confidence Estimation and Calibration**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.08298)]\\\\n* **Shortcut Learning of Large Language Models in Natural Language Understanding**, COMMUN ACM 2023.12 [[Paper](https://dl.acm.org/doi/10.1145/3596490)]\\\\n* **Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.03188)] [[GitHub](https://github.com/teacherpeterpan/self-correction-llm-papers)]\\\\n\\\\n#### Efficient LLMs\\\\n\\\\n* **Efficient Large Language Models: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.03863)] [[GitHub](https://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey)]\\\\n* **LLM Inference Unveiled: Survey and Roofline Model Insights**, arXiv 2024.03 [[Paper](https://arxiv.org/abs/2402.16363)]\\\\n* **Towards Efficient Generative Large Language Model Serving: A Survey from Algorithms to Systems**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.15234)]\\\\n* **A Survey on Model Compression for Large Language Models**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.07633)]\\\\n* **A Comprehensive Survey of Compression Algorithms for Language Models**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.15347)]\\\\n* **The Efficiency Spectrum of Large Language Models: An Algorithmic Survey**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.10844)] [[GitHub](https://github.com/tding1/Efficient-LLM-Survey)]\\\\n* **Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.12148)]\\\\n* **Model Compression and Efficient Inference for Large Language Models: A Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.09748)]\\\\n* **Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.07851)] [[GitHub](https://github.com/hemingkx/SpeculativeDecodingPapers)]\\\\n* **A Survey on Hardware Accelerators for Large Language Models**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.09890)]\\\\n\\\\n#### Learning Methods\\xa0for LLMs\\\\n\\\\n* **Knowledge Unlearning for LLMs: Tasks, Methods, and Challenges**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.15766)]\\\\n* **Continual Learning with Pre-Trained Models: A Survey**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.16386)] [[GitHub](https://github.com/sun-hailong/LAMDA-PILOT)]\\\\n* **Continual Learning for Large Language Models: A Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.01364)]\\\\n* **Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning**, arXiv 2023.03 [[Paper](https://arxiv.org/pdf/2303.15647)]\\\\n\\\\n#### Multimodal LLMs\\\\n\\\\n* **Vision-Language Instruction Tuning: A Review and Analysis**, arXiv 2023,11 [[Paper](https://arxiv.org/abs/2311.08172)] [[GitHub](https://github.com/palchenli/VL-Instruction-Tuning)]\\\\n* **Large Language Models Meet Computer Vision: A Brief Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.16673)]\\\\n* **Foundational Models Defining a New Era in Vision: A Survey and Outlook**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.13721)] [[GitHub](https://github.com/awaisrauf/Awesome-CV-Foundational-Models)]\\\\n* **Video Understanding with Large Language Models: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.17432)] [[GitHub](https://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding)]\\\\n* **Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.10196)] [[GitHub](https://github.com/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM)]\\\\n* **Sparks of large audio models: A survey and outlook**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.12792)] [[GitHub](https://github.com/EmulationAI/awesome-large-audio-models)]\\\\n* **How to Bridge the Gap between Modalities: A Comprehensive Survey on Multimodal Large Language Model**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.07594)]\\\\n* **A Survey on Multimodal Large Language Models**, arXiv 2023.06 [[Paper](https://arxiv.org/abs/2306.13549)]\\\\n* **Multimodal Large Language Models: A Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.13165)]\\\\n\\\\n#### Knowledge Based LLMs\\\\n\\\\n###### Retrieval-Augmented LLMs\\\\n\\\\n* **Building trust in conversational ai: A comprehensive review and solution architecture for explainable, privacy-aware systems using llms and knowledge graph**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.13534)]\\\\n* **A Survey on Retrieval-Augmented Text Generation**, arXiv 2022.02 [[Paper](https://arxiv.org/abs/2202.01110)]\\\\n* **Retrieval-Augmented Generation for Large Language Models: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.10997)] [[GitHub](https://github.com/Tongji-KGLLM/RAG-Survey)]\\\\n\\\\n###### Knowledge Editing\\\\n\\\\n* **Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.05876)]\\\\n* **Knowledge Editing for Large Language Models: A Survey**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.16218)]\\\\n* **Editing Large Language Models: Problems, Methods, and Opportunities**, arXiv 2023.05 [[Paper](https://arxiv.org/abs/2305.13172)]\\\\n\\\\n#### Extension of LLMs\\\\n\\\\n###### LLMs with\\xa0Tools\\\\n\\\\n* **A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond**, arXiv 2024.03 [[Paper](https://arxiv.org/abs/2403.14734)] [[GitHub](https://github.com/QiushiSun/NCISurvey)]\\\\n* **Foundation Models for Decision Making: Problems, Methods, and Opportunities**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.04129)]\\\\n* **Augmented Language Models: a Survey**, arXiv 2023.02 [[Paper](https://arxiv.org/abs/2302.07842)]\\\\n* **Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.17903)] [[GitHub](https://github.com/yueyueL/ReliableLM4Code)]\\\\n* **Large Language Models Meet NL2Code: A Survey**, arXiv 2022.12 [[Paper](https://arxiv.org/abs/2212.09420)]\\\\n\\\\n###### LLMs and\\xa0Interactions\\\\n\\\\n* **Large Language Models for Robotics: A Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.07226)]\\\\n* **A Survey on Multimodal Large Language Models for Autonomous Driving**, WACV workshop 2023.11 [[Paper](https://openaccess.thecvf.com/content/WACV2024W/LLVM-AD/papers/Cui_A_Survey_on_Multimodal_Large_Language_Models_for_Autonomous_Driving_WACVW_2024_paper.pdf)]\\\\n* **LLM4Drive: A Survey of Large Language Models for Autonomous Driving**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.01043v3)] [[GitHub](https://github.com/Thinklab-SJTU/Awesome-LLM4AD)]\\\\n* **A Survey on Large Language Model based Autonomous Agents**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.11432)] [[GitHub](https://github.com/Paitesanshi/LLM-Agent-Survey)]\\\\n* **The Rise and Potential of Large Language Model Based Agents: A Survey**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.07864)] [[GitHub](https://github.com/WooooDyy/LLM-Agent-Paper-List)]\\\\n* **Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.11970)]\\\\n* **Large Multimodal Agents: A Survey**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.15116)] [[GitHub](https://github.com/jun0wanan/awesome-large-multimodal-agents)]\\\\n* **Role play with large language models**, arXiv 2023.11 [[Paper](https://www.nature.com/articles/s41586-023-06647-8)]\\\\n\\\\n#### Long Sequence LLMs\\\\n\\\\n* **Advancing Transformer Architecture in Long-Context Large Language Models: A Comprehensive Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.12351)]\\\\n* **Length Extrapolation of Transformers: A Survey from the Perspective of Position Encoding**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.17044)]\\\\n\\\\n#### LLMs Applications\\\\n\\\\n###### Education\\\\n\\\\n* **ChatGPT and Beyond: The Generative AI Revolution in Education**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.15198)]\\\\n* **ChatGPT and large language models in academia: opportunities and challenges**, arXiv 2023.07 [[Paper](https://link.springer.com/article/10.1186/s13040-023-00339-9)]\\\\n* **ChatGPT for good? On opportunities and challenges of large language models for education**, arXiv 2023.04 [[Paper](https://www.sciencedirect.com/science/article/abs/pii/S1041608023000195)]\\\\n\\\\n###### Law\\\\n\\\\n* **Large Language Models in Law: A Survey**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2312.03718)]\\\\n* **A short survey of viewing large language models in legal aspect**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.09136)]\\\\n\\\\n###### Healthcare\\\\n\\\\n* **A Survey of Large Language Models in Medicine: Progress, Application, and Challenge**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.05112)] [[GitHub](https://github.com/AI-in-Health/MedLLMsPracticalGuide)]\\\\n* **Large Language Models Illuminate a Progressive Pathway to Artificial Healthcare Assistant: A Review**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.01918)] [[GitHub](https://github.com/mingze-yuan/Awesome-LLM-Healthcare)]\\\\n* **Large AI Models in Health Informatics: Applications, Challenges, and the Future**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.11568)] [[GitHub](https://github.com/Jianing-Qiu/Awesome-Healthcare-Foundation-Models)]\\\\n* **A SWOT (Strengths, Weaknesses, Opportunities, and Threats) Analysis of ChatGPT in the Medical Literature: Concise Review**, JMIR 2023.11 [[Paper](https://www.jmir.org/2023/1/e49368/)]\\\\n* **ChatGPT in Healthcare: A Taxonomy and Systematic Review**, Computer Methods and Programs in Biomedicine 2024.01 [[Paper](https://www.sciencedirect.com/science/article/pii/S0169260724000087)]\\\\n* **A review of the explainability and safety of conversational agents for mental health to identify avenues for improvement**, NCBI 2023.10 [[Paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10601652/)]\\\\n* **Towards a Psychological Generalist AI: A Survey of Current Applications of Large Language Models and Future Prospects**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.04578)]\\\\n* **Large Language Models in Mental Health Care: a Scoping Review**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.02984)]\\\\n* **The utility of ChatGPT as an example of large language models in healthcare education, research and practice: Systematic review on the future perspectives and**, arXiv 2023.12 [[Paper](https://www.medrxiv.org/content/10.1101/2023.02.19.23286155v1)]\\\\n* **The imperative for regulatory oversight of large language models (or generative AI) in healthcare**, arXiv 2023.07 [[Paper](https://www.nature.com/articles/s41746-023-00873-0)]\\\\n* **A Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability and Ethics**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.05694)] [[GitHub](https://github.com/KaiHe-better/LLM-for-Healthcare)]\\\\n* **The Shaky Foundations of Clinical Foundation Models: A Survey of Large Language Models and Foundation Models for EMRs**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.12961)]\\\\n\\\\n###### Games\\\\n\\\\n* **Large Language Models and Games: A Survey and Roadmap**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.18659)]\\\\n* **Large Language Models and Video Games: A Preliminary Scoping Review**, arXiv 2024.03 [[Paper](https://arxiv.org/abs/2403.02613)]\\\\n\\\\n###### NLP Tasks\\\\n\\\\n* **Large Language Models for Information Retrieval: A Survey**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.07107)] [[GitHub](https://github.com/RUC-NLPIR/LLM4IR-Survey)]\\\\n* **Large Language Models for Generative Information Extraction: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.17617)] [[GitHub](https://github.com/quqxui/Awesome-LLM4IE-Papers)]\\\\n* **Recent Advances in Natural Language Processing via Large Pre-Trained Language Models: A Survey**, arXiv 2021.11 [[Paper](https://arxiv.org/abs/2111.01243)]\\\\n* **If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2401.00812)]\\\\n\\\\n###### Software Engineering\\\\n\\\\n* **Large Language Models for Software Engineering: Survey and Open Problems**, arXiv 2023.10 [[Paper](https://arxiv.org/abs/2310.03533)]\\\\n* **Large Language Models for Software Engineering: A Systematic Literature Review**, arXiv 2023.08 [[Paper](https://arxiv.org/abs/2308.10620)]\\\\n* **Software Testing with Large Language Models: Survey, Landscape, and Vision**, arXiv 2023.07 [[Paper](https://arxiv.org/abs/2307.07221)]\\\\n* **Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code**, arXiv 2024.01 [[Paper](https://arxiv.org/abs/2311.07989)] [[GitHub](https://github.com/codefuse-ai/Awesome-Code-LLM)]\\\\n\\\\n###### Recommender Systems\\\\n\\\\n* **Foundation Models for Recommender Systems: A Survey and New Perspectives**, arXiv 2024.02 [[Paper](https://arxiv.org/abs/2402.11143)]\\\\n* **User Modeling in the Era of Large Language Models: Current Research and Future Directions**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2312.11518)] [[GitHub](https://github.com/TamSiuhin/LLM-UM-Reading)]\\\\n* **A Survey on Large Language Models for Personalized and Explainable Recommendations**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.12338)]\\\\n* **Large Language Models for Generative Recommendation: A Survey and Visionary Discussions**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.01157)]\\\\n* **A Survey on Large Language Models for Recommendation**, arXiv 2023.05 [[Paper](https://arxiv.org/abs/2305.19860)] [[GitHub](https://github.com/WLiK/LLM4Rec)]\\\\n* **How Can Recommender Systems Benefit from Large Language Models: A Survey**, arXiv 2023.06 [[Paper](https://arxiv.org/abs/2306.05817)] [[GitHub](https://github.com/CHIANGEL/Awesome-LLM-for-RecSys/)]\\\\n\\\\n* **A Survey of Graph Meets Large Language Model: Progress and Future Directions**, arXiv 2023.11 [[Paper](https://arxiv.org/abs/2311.12399)]\\\\n* **Large Language Models on Graphs: A Comprehensive Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.02783)] [[GitHub](https://github.com/PeterGriffinJin/Awesome-Language-Model-on-Graphs)]\\\\n* **The Contribution of Knowledge in Visiolinguistic Learning: A Survey on Tasks and Challenges**, arXiv 2023.03 [[Paper](https://arxiv.org/abs/2303.02411)]\\\\n\\\\n* **Large Language Models in Finance: A Survey**, ICAIF 2023.11 [[Paper](https://dl.acm.org/doi/10.1145/3604237.3626869)]\\\\n* **Mathematical Language Models: A Survey**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.07622)]\\\\n* **Recent applications of AI to environmental disciplines: A review**, SCI TOTAL ENVIRON 2023.10 [[Paper](https://www.sciencedirect.com/science/article/pii/S0048969723063325?casa_token=sbh1pxIYyAgAAAAA:f3WytHabl8udc5v8OhRunnwHEemEAwNafzAcP2reVdGKMAJ-4EcJIxwKO4gdE8ozb6ZibbcY2_4)]\\\\n* **Opportunities and Challenges of Applying Large Language Models in Building Energy Efficiency and Decarbonization Studies: An Exploratory Overview**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.11701)]\\\\n* **When Large Language Models Meet Citation: A Survey**, arXiv 2023.09 [[Paper](https://arxiv.org/abs/2309.09727)]\\\\n* **A Survey of Text Watermarking in the Era of Large Language Models**, arXiv 2023.12 [[Paper](https://arxiv.org/abs/2312.07913)]\\\\n* **The future of gpt: A taxonomy of existing chatgpt research, current challenges, and possible future directions**, SSRN 2023.04 [[Paper](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4413921)]\\\\n* **Summary of ChatGPT-Related Research and Perspective Towards the Future of Large Language Models**, Meta-Radiology 2023.09 [[Paper](https://www.sciencedirect.com/science/article/pii/S2950162823000176)]\\\\n\\\\nWe would like to thank the people who have contributed to this project. The core contributors are\\\\n\\\\n*Junhao Ruan, Long Meng, Weiqiao Shan, Tong Xiao, Jingbo Zhu*\\\\n\\\\n## About\\\\n\\\\nA collection of 150+ surveys on LLMs\\\\n\\\\n### Resources\\\\n\\\\n### License\\\\n\\\\n[CC0-1.0 license](#CC0-1.0-1-ov-file)\\\\n\\\\n### Uh oh!\\\\n\\\\nThere was an error while loading. Please reload this page.\\\\n\\\\n[Custom properties](/NiuTrans/ABigSurveyOfLLMs/custom-properties)\\\\n\\\\n### Stars\\\\n\\\\n[**342** stars](/NiuTrans/ABigSurveyOfLLMs/stargazers)\\\\n\\\\n### Watchers\\\\n\\\\n[**6** watching](/NiuTrans/ABigSurveyOfLLMs/watchers)\\\\n\\\\n### Forks\\\\n\\\\n[**26** forks](/NiuTrans/ABigSurveyOfLLMs/forks)\\\\n\\\\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FNiuTrans%2FABigSurveyOfLLMs&report=NiuTrans+%28user%29)\\\\n\\\\n## [Releases](/NiuTrans/ABigSurveyOfLLMs/releases)\\\\n\\\\nNo releases published\\\\n\\\\n## [Packages 0](/orgs/NiuTrans/packages?repo_name=ABigSurveyOfLLMs)\\\\n\\\\nNo packages published\\\\n\\\\n## [Contributors 4](/NiuTrans/ABigSurveyOfLLMs/graphs/contributors)\\\\n\\\\n### Uh oh!\\\\n\\\\nThere was an error while loading. Please reload this page.\\\\n\\\\nYou can’t perform that action at this time.\\\\n\\\\n \"}], \"response_time\": 5.95, \"request_id\": \"de73280e-685d-4cb6-b1c5-396e93aef7ca\"}', name='tavily_search', id='29a23fb9-de0d-4b9d-9cdf-ad6d3fe16a4b', tool_call_id='call_afJIDcLuyfzldcrw3r6CqXzC'),\n",
       " AIMessage(content='LLM(대규모 언어 모델)에 대한 최근 연구와 발전을 다룬 여러 논문들을 다음과 같이 요약할 수 있습니다:\\n\\n1. **A Survey of Large Language Models** ([Link to Paper](https://arxiv.org/abs/2303.18223)):\\n   - 이 논문은 LLM의 배경, 주요 발견 및 최신 기술을 소개합니다. LLM은 사전 훈련, 파라미터 조정, 활용 및 평가와 같은 네 가지 주요 측면에 집중하여, 모델의 규모가 성능 향상에 어떻게 기여하는지를 설명합니다. ChatGPT 등 LLM의 발전이 AI 커뮤니티에 미치는 영향을 논의하며, LLM 개발에 필요한 자원과 향후 방향에 대해서도 언급합니다.\\n\\n2. **Employing Large Language Models in Survey Research** ([Link to Article](https://www.sciencedirect.com/science/article/pii/S2949719123000171)):\\n   - 이 기사에서는 LLM이 설문 조사 연구에 어떻게 활용될 수 있는지를 다룹니다. LLM은 질문 작성 및 응답 편향 문제를 해결하는 데 도움을 줄 수 있지만, 샘플링 편향이나 비응답 편향은 해결하지 못하는 한계를 가지고 있습니다. LLM은 다른 방법과 함께 사용될 때 그 유용성을 극대화할 수 있습니다.\\n\\n3. **NiuTrans/ABigSurveyOfLLMs** ([GitHub Repository](https://github.com/NiuTrans/ABigSurveyOfLLMs)):\\n   - 이 GitHub 저장소는 150개 이상의 LLM 관련 설문을 모은 컬렉션으로, LLM의 발전과 관련된 다양한 연구 결과를 제공합니다. 이 자료는 LLM에 대한 포괄적인 개요를 원하시는 분들에게 유용할 것입니다.\\n\\n이번 연구들은 LLM이 AI 분야에서 중요한 발전을 이루고 있음을 보여주며, 설문 조사나 다양한 연구 영역에서의 활용 가능성을 탐색하고 있습니다. LLM의 진화를 통해 AI 알고리즘 개발 방식이 혁신적으로 변화할 것으로 기대됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 447, 'prompt_tokens': 17009, 'total_tokens': 17456, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1920}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-Cqaq9mkRzwZfGE1DxQuDX71wTZmvj', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5496-70f6-75a3-b4ab-1d4605b56559-0', usage_metadata={'input_tokens': 17009, 'output_tokens': 447, 'total_tokens': 17456, 'input_token_details': {'audio': 0, 'cache_read': 1920}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
